{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e362b79a-135f-480b-a8ac-20b496d6ec57",
   "metadata": {},
   "source": [
    "### This code cell extracts pixel values from the images with the added indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121f87e-d0d3-443e-a356-1f6624c54e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "images_path = r'C:\\Users\\SkosanaT\\Documents\\RGB_test\\npy_tiff'\n",
    "\n",
    "# Get file path list of all TIFF images in dir\n",
    "imagelist = [os.path.join(images_path, file) for file in os.listdir(images_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "print(imagelist)\n",
    "\n",
    "# Initialize dictionaries\n",
    "imgvals = {}\n",
    "\n",
    "# Open shapefile and extract points' coordinates [0]= x coordinate, [1]= y coordinate  and attributes\n",
    "with fiona.open(pntsshp_path, 'r') as shapefile:\n",
    "    points = [[(point['geometry']['coordinates'][0], point['geometry']['coordinates'][1]),\n",
    "               (int(point['properties']['ID']), point['properties']['Val_id']),\n",
    "               (point['properties']['X'], point['properties']['Y'])] for point in shapefile]\n",
    "    #for point in shapefile:\n",
    "        #print(point['properties']['ID'])\n",
    "\n",
    "# Initialize dictionary to store band pixel values associated with each point\n",
    "point_pixel_values = {}\n",
    "\n",
    "# Iterate over each raster image\n",
    "for imagepath in imagelist:\n",
    "    with rasterio.open(imagepath) as src:\n",
    "        \n",
    "        # Initialize dictionaries for current image\n",
    "        imagename = os.path.splitext(os.path.basename(imagepath))[0] #splittext removes the extension from files.\n",
    "        \n",
    "        # Iterate over each band\n",
    "        for band in range(1, src.count + 1):\n",
    "            \n",
    "            # Initialize dictionary for current band\n",
    "            band_pixel_values = {}\n",
    "\n",
    "            # Iterate over each point and extract pixel values\n",
    "            for point in points:\n",
    "                row, col = src.index(point[0][0], point[0][1]) # Find the point within the raster image\n",
    "                values = src.read(band, window=((row, row+1), (col, col+1))) # Read the band values \n",
    "               \n",
    "\n",
    "                if values.size != 0: # Check if bands are valid/not empty\n",
    "                    # Populate band_pixel_values dictionary\n",
    "                    band_pixel_values[f'Band_{band}'] = values[0][0]\n",
    "                    \n",
    "                    # Add band_pixel_values to point_pixel_values for the current point\n",
    "                    point_key = str(\"Point_id: {}, X: {}, Y: {}, Class_ID: {}\".format(point[1][1], point[2][0], point[2][1], point[1][0] ))\n",
    "                    if point_key not in point_pixel_values:\n",
    "                        point_pixel_values[point_key] = {}\n",
    "                    point_pixel_values[point_key].update(band_pixel_values)\n",
    "                   \n",
    "                         \n",
    "# Print point_pixel_values\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    print(f\"Point: {point_key}, Pixel Values: {pixel_values}, Image name: {imagename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f0572-dbf3-4960-9407-870044ca8f2b",
   "metadata": {},
   "source": [
    "### This cell changes point_pixel_value dictionary to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46d343-d33d-46e3-ad9f-cc2984faa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for DataFrame creation\n",
    "data_list = []\n",
    "\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    data_dict = {}\n",
    "    # Extracting Point ID, X, Y, and Class ID from point_key\n",
    "    point_id = point_key.split(',')[0].split(':')[1].strip()  \n",
    "    x_coord = point_key.split(',')[1].split(':')[1].strip()\n",
    "    y_coord = point_key.split(',')[2].split(':')[1].strip()\n",
    "    class_id = point_key.split(',')[3].split(':')[1].strip()\n",
    "    \n",
    "    # Add extracted information as separate columns\n",
    "    data_dict['Point'] = point_id\n",
    "    data_dict['X'] = x_coord\n",
    "    data_dict['Y'] = y_coord\n",
    "    data_dict['Class_ID'] = class_id\n",
    "    \n",
    "    # Add band pixel values as columns\n",
    "    data_dict.update(pixel_values)\n",
    "\n",
    "    data_list.append(data_dict)\n",
    "\n",
    "# Create DataFrame from list of dictionaries\n",
    "pixelvalues_df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame (optional)\n",
    "print(pixelvalues_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = r'C:\\Users\\SkosanaT\\Documents\\RGB_test\\Band_values\\pixel_values.csv'\n",
    "pixelvalues_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'DataFrame successfully saved to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f5186-a040-45db-9354-0d44f42f4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "#pixelvalues_df = pd.read_csv(r'E:\\SPOT6_7\\SPOT6_7\\BandValues\\pixel_values.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(pixelvalues_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f62fc9-0b00-40d9-80dc-e707d18f08f1",
   "metadata": {},
   "source": [
    "### This cell block trains the random forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352804a-fed1-4d9b-b81d-bb6881679f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features \n",
    "features = pixelvalues_df[['Band_1', 'Band_2', 'Band_3', 'Band_4', 'Band_5', 'Band_6', 'Band_7', 'Band_8', 'Band_9']]\n",
    "\n",
    "# Define target (Class ID column)\n",
    "target = pixelvalues_df['Class_ID']\n",
    "\n",
    "# Convert features and target columns to arrays\n",
    "features_array = features.values\n",
    "target_array = target.values\n",
    "\n",
    "# Train the classifier using RandomForest with 500 trees\n",
    "classifier = RandomForestClassifier(n_estimators=500)\n",
    "classifier.fit(features_array, target_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52995832-a356-42b0-aa72-088d8dc22565",
   "metadata": {},
   "source": [
    "### This cell block performs the classification on each image in the folder using the trained classifer in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798b018-51ec-4a1f-842a-b4a5426e6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want to save the classified images\n",
    "output_folder = r\"C:\\Users\\SkosanaT\\Documents\\RGB_test\\Classified\"\n",
    "\n",
    "# Check if the output folder exists, if not, create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each image in the collection\n",
    "for image_path in imagelist:\n",
    "    \n",
    "    # Open the image using rasterio\n",
    "    with rasterio.open(image_path) as src:\n",
    "        # Get the shape of the image\n",
    "        rows, cols = src.height, src.width\n",
    "        \n",
    "        # Define batch size (adjust as needed based on memory constraints)\n",
    "        batch_size = 1000  # You can adjust this value\n",
    "        \n",
    "        # Initialize the classification result array for the entire image\n",
    "        classification_result = np.zeros((rows, cols), dtype=np.uint8)\n",
    "        \n",
    "        # Iterate over the image in batches\n",
    "        for row_start in range(0, rows, batch_size):\n",
    "            for col_start in range(0, cols, batch_size):\n",
    "                row_end = min(row_start + batch_size, rows)\n",
    "                col_end = min(col_start + batch_size, cols)\n",
    "        \n",
    "                # Read the batch of bands\n",
    "                bands = [src.read(band_idx, window=((row_start, row_end), (col_start, col_end))) \n",
    "                         for band_idx in range(1, src.count + 1)]\n",
    "                \n",
    "                # Stack the bands into a single array\n",
    "                stacked_bands = np.stack(bands, axis=-1)\n",
    "                \n",
    "                # Reshape the array to 2D (rows * cols, num_bands) for classification\n",
    "                reshaped_bands = stacked_bands.reshape(-1, stacked_bands.shape[-1])\n",
    "                \n",
    "                # Mask out no data values (pixels with a value of 0)\n",
    "                valid_pixels_mask = np.all(reshaped_bands != 0, axis=1)\n",
    "                valid_pixels = reshaped_bands[valid_pixels_mask]\n",
    "                \n",
    "                # Predict using the trained classifier\n",
    "                predicted_labels = np.zeros(reshaped_bands.shape[0], dtype=np.uint8)\n",
    "                predicted_labels[valid_pixels_mask] = classifier.predict(valid_pixels)\n",
    "                \n",
    "                # Reshape the predicted labels back to the 2D batch\n",
    "                predicted_labels_2d = predicted_labels.reshape(row_end - row_start, col_end - col_start)\n",
    "                \n",
    "                # Place the classified batch back into the classification result array\n",
    "                classification_result[row_start:row_end, col_start:col_end] = predicted_labels_2d\n",
    "        \n",
    "        # Construct the output file path\n",
    "        output_filename = os.path.basename(image_path).replace('.tif', '_classified.tif')\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        # Prepare metadata for the classified image\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'driver': 'GTiff',\n",
    "            'dtype': 'uint8',  # Ensure data type is appropriate for classification results\n",
    "            'count': 1,  # Single band\n",
    "            'compress': 'lzw',  # Compression method (Lempel-Ziv-Welch)\n",
    "            'nodata': 0,  # Optional: Set nodata value\n",
    "            'crs': src.crs,  # Use the same CRS as the input raster\n",
    "            'transform': src.transform,  # Use the same transform as the input raster\n",
    "        })\n",
    "        \n",
    "        # Write the classified image to a new GeoTIFF file\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(classification_result, 1)\n",
    "\n",
    "print(\"Classification completed and classified images saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02925644-2c16-44f4-b0e7-1f4b7e11382c",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd7947-fca2-460a-9932-a3ef47ebedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define the paths\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "umzim_boundary = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\Fieldwork\\uMzimvubuFieldTrip\\uMzimvubuBoundary.shp'\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Check if there are any valid geometries\n",
    "        if not valid_points.empty and not valid_points.geometry.is_empty.all():\n",
    "            # Rasterize validation points onto classified image to extract pixel values\n",
    "            transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                    classified_image.res[0], classified_image.res[1])\n",
    "            rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                               out_shape=classified_image_data.shape,\n",
    "                                               transform=transform,\n",
    "                                               dtype='uint8')\n",
    "\n",
    "            # Extract pixel values from classified image corresponding to validation points\n",
    "            classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "            # Get ground truth labels corresponding to valid points\n",
    "            ground_truth_labels = valid_points['ID']\n",
    "\n",
    "            # Append to overall lists\n",
    "            all_ground_truth_labels.extend(ground_truth_labels)\n",
    "            all_classified_values.extend(classified_values)\n",
    "        else:\n",
    "            print(\"No valid geometries found for rasterization within the raster boundary.\")\n",
    "\n",
    "# Calculate overall accuracy metrics\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values)\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = np.unique(np.concatenate((all_ground_truth_labels, all_classified_values)))\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Specify the save location\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Overallaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47210256-b205-4742-b51c-a872a596d20e",
   "metadata": {},
   "source": [
    "## Inter accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaac01-4c3d-416b-be6e-999936c27117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return 1  # Invasive alien class\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 2  # Non-invasive alien class\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Invasive Alien', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Interaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7058987-4fea-4ef0-a27a-be0269734efe",
   "metadata": {},
   "source": [
    "### Intra accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a86a9a-3fe4-447d-9c6f-5d502ac1db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return class_id  # Keep individual classes 1 to 6\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 7  # Group classes 7 to 15 together as class 7\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Alien_Black Wattle', 'Alien_Gum', 'Alien_Other', 'Alien_Pine', 'Alien Poplar', 'Alien Silver Wattle', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Create a Pandas DataFrame for overall accuracy\n",
    "overall_accuracy_df = pd.DataFrame([overall_accuracy], columns=['Overall Accuracy'])\n",
    "\n",
    "# Specify the save location\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Intraaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
