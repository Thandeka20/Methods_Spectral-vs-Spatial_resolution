{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baad9d88-d84a-4fae-9a4d-5dc70650ab94",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab815866-e19e-4290-be97-ed500dbb6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "import os\n",
    "import rasterio\n",
    "import fiona\n",
    "import json\n",
    "import csv\n",
    "from rasterio.merge import merge\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import Affine\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670472a7-78ff-40b8-adff-f1e72a6a514e",
   "metadata": {},
   "source": [
    "# This code loops through a folder to count the number of tiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e63f274-0f68-4962-96c0-08aabb8cf11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TIFF files found: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder\n",
    "RGB_folder = r'H:\\Aerial_photographs'\n",
    "RGB_folder = r'H:\\Aerial_photos'\n",
    "\n",
    "# Initialize a counter for the number of TIFF files\n",
    "tif_count = 0\n",
    "\n",
    "# Iterate through all the directories and files in the root folder\n",
    "for dirpath, dirnames, filenames in os.walk(RGB_folder):\n",
    "    # Iterate through the files in the current directory\n",
    "    for filename in filenames:\n",
    "        # Check if the file has a TIFF extension\n",
    "        if filename.endswith('.tif'):\n",
    "            # Increment the counter if it's a TIFF file\n",
    "            tif_count += 1\n",
    "\n",
    "# Print the total count of TIFF files found\n",
    "print(\"Total TIFF files found:\", tif_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3d71a-7cc2-4aca-a9ca-9821d751bf14",
   "metadata": {},
   "source": [
    "# Rescale bands and save the tif files as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc59c2a-3f42-4ce7-8ae3-f9c69b45cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder '3129AA':\n",
      "[1/5] Image saved as H:\\Aerial_photographs\\numpy_array\\3129AA_01_2020_1386_RGB_RECT.npy\n",
      "Skipping '3129AA_01_2020_1386_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "[2/5] Image saved as H:\\Aerial_photographs\\numpy_array\\3129AA_02_2020_1386_RGB_RECT.npy\n",
      "Skipping '3129AA_02_2020_1386_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "[3/5] Image saved as H:\\Aerial_photographs\\numpy_array\\3129AA_03_2020_1386_RGB_RECT.npy\n",
      "Skipping '3129AA_03_2020_1386_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "[4/5] Image saved as H:\\Aerial_photographs\\numpy_array\\3129AA_04_2020_1386_RGB_RECT.npy\n",
      "Skipping '3129AA_04_2020_1386_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3129AA_05_2020_1386_RGB_RECT.tfw' as it's not a valid TIFF file.\n",
      "[5/5] Image saved as H:\\Aerial_photographs\\numpy_array\\3129AA_05_2020_1386_RGB_RECT.npy\n",
      "Skipping '3129AA_05_2020_1386_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping 'numpy_array' as it's not a directory or it's the 'RESULTS' folder.\n"
      "Processing folder '3128BB':\n",
      "[1/5] Image saved as H:\\Aerial_photos\\numy_array\\3128BB_01_2021_1384_RGB_RECT.npy\n",
      "Skipping '3128BB_01_2021_1384_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_01_2021_1384_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "[2/5] Image saved as H:\\Aerial_photos\\numy_array\\3128BB_02_2021_1384_RGB_RECT.npy\n",
      "Skipping '3128BB_02_2021_1384_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_02_2021_1384_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "[3/5] Image saved as H:\\Aerial_photos\\numy_array\\3128BB_03_2021_1384_RGB_RECT.npy\n",
      "Skipping '3128BB_03_2021_1384_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_03_2021_1384_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "[4/5] Image saved as H:\\Aerial_photos\\numy_array\\3128BB_04_2021_1384_RGB_RECT.npy\n",
      "Skipping '3128BB_04_2021_1384_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_04_2021_1384_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "[5/5] Image saved as H:\\Aerial_photos\\numy_array\\3128BB_05_2021_1384_RGB_RECT.npy\n",
      "Skipping '3128BB_05_2021_1384_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_05_2021_1384_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "Processing folder 'numy_array':\n",
      "Skipping '3128BB_01_2021_1384_RGB_RECT.npy' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_02_2021_1384_RGB_RECT.npy' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_03_2021_1384_RGB_RECT.npy' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_04_2021_1384_RGB_RECT.npy' as it's not a valid TIFF file.\n",
      "Skipping '3128BB_05_2021_1384_RGB_RECT.npy' as it's not a valid TIFF file.\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to save the updated images\n",
    "output_folder = r'H:\\Aerial_photographs\\numpy_array'\n",
    "output_folder = r'H:\\Aerial_photos\\numy_array'\n",
    "\n",
    "# Initialize a counter for progress tracking\n",
    "total_files = 0\n",
    "processed_files = 0\n",
    "\n",
    "# Calculate the total number of TIFF files to process\n",
    "for folder_name in os.listdir(RGB_folder):\n",
    "    folder_path = os.path.join(RGB_folder, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name != 'numpy_array':\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            if os.path.isfile(os.path.join(folder_path, image_file)) and (image_file.endswith('.tif') or image_file.endswith('.TIF')):\n",
    "                total_files += 1\n",
    "\n",
    "# Loop through each folder in the directory\n",
    "for folder_name in os.listdir(RGB_folder):\n",
    "    folder_path = os.path.join(RGB_folder, folder_name)\n",
    "\n",
    "    # Check if the item is a directory and skip 'RESULTS'\n",
    "    if os.path.isdir(folder_path) and folder_name != 'numpy_array':\n",
    "        print(f\"Processing folder '{folder_name}':\")\n",
    "\n",
    "        # Loop through each image file in the folder\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            # Construct full path to the image file\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "            # Check if it's a file and if it ends with .tif or .TIF\n",
    "            if os.path.isfile(image_path) and (image_file.endswith('.tif') or image_file.endswith('.TIF')):\n",
    "                try:\n",
    "                    # Open the image and read all bands\n",
    "                    with rasterio.open(image_path) as img:\n",
    "                        full_img = img.read()\n",
    "\n",
    "                    # Rescale the image bands by dividing each band by 2.5\n",
    "                    rescaled_img = full_img / 2.5\n",
    "\n",
    "                    # Save the rescaled image array to a .npy file for later use\n",
    "                    output_filename = f'{os.path.splitext(image_file)[0]}.npy'\n",
    "                    output_path = os.path.join(output_folder, output_filename)\n",
    "                    np.save(output_path, rescaled_img)\n",
    "\n",
    "                    # Increment the counter and print progress\n",
    "                    processed_files += 1\n",
    "                    print(f\"[{processed_files}/{total_files}] Image saved as {output_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing '{image_file}': {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping '{image_file}' as it's not a valid TIFF file.\")\n",
    "    else:\n",
    "        print(f\"Skipping '{folder_name}' as it's not a directory or it's the 'numpy_array' folder.\")\n"
    "        print(f\"Skipping '{folder_name}' as it's not a directory or it's the 'RESULTS' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5bc295-33b4-4cd4-ba12-cb0b6753898d",
   "metadata": {},
   "source": [
    "# Check that the files load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 2,
   "id": "688b6f48-d6f5-4a85-98e7-b76d1a1e24e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'updated_3129AA_01_2020_1386_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23379, 20301)\n",
      "File 'updated_3129AA_02_2020_1386_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23387, 20311)\n",
      "File 'updated_3129AA_03_2020_1386_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23396, 20321)\n",
      "File 'updated_3129AA_04_2020_1386_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23405, 20331)\n",
      "File 'updated_3129AA_05_2020_1386_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23413, 20341)\n"
      "File 'updated_3128BB_01_2021_1384_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23413, 20341)\n",
      "File 'updated_3128BB_03_2021_1384_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23396, 20321)\n",
      "File 'updated_3128BB_04_2021_1384_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23387, 20311)\n",
      "File 'updated_3128BB_05_2021_1384_RGB_RECT.npy' loaded successfully\n",
      "Shape: (4, 23379, 20301)\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'H:\\Aerial_photographs\\gi_index'  # Replace with your folder path\n",
    "folder_path = r'H:\\Aerial_photos\\numy_array'  # Replace with your folder path\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            data = np.load(file_path)\n",
    "            print(f\"File '{filename}' loaded successfully\")\n",
    "            print(f\"Shape: {data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file '{filename}': {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119586cb-a7fc-4e17-830f-3cedf6ff73c5",
   "metadata": {},
   "source": [
    "# Read bands and calculate indices\n",
    "#### Greenness Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": null,
   "id": "5dfdd7b2-f2d0-41f9-8b4f-c8c93f0f0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: H:\\Aerial_photographs\\numpy_array\\3129AA_01_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23379x20301\n",
      "Processed and saved as H:\\Aerial_photographs\\gi_index\\updated_3129AA_01_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\numpy_array\\3129AA_02_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23387x20311\n",
      "Processed and saved as H:\\Aerial_photographs\\gi_index\\updated_3129AA_02_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\numpy_array\\3129AA_03_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23396x20321\n",
      "Processed and saved as H:\\Aerial_photographs\\gi_index\\updated_3129AA_03_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\numpy_array\\3129AA_04_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23405x20331\n",
      "Processed and saved as H:\\Aerial_photographs\\gi_index\\updated_3129AA_05_2020_1386_RGB_RECT.npy\n"
      "Processing file: H:\\Aerial_photos\\numy_array\\3128BB_02_2021_1384_RGB_RECT.npy\n",
      "Image dimensions: 23405x20331\n"
     ]
    }
   ],
   "source": [
    "# Define output folder\n",
    "gi_index = r'H:\\Aerial_photographs\\gi_index'\n",
    "# Create a folder to save the updated images\n",
    "output_folder = r'H:\\Aerial_photos\\numy_array'\n",
    "# Define output folder\n",
    "gi_index = r'H:\\Aerial_photos\\gi_index'\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(gi_index, exist_ok=True)\n",
    "\n",
    "# Define chunk size (e.g., 512x512 pixels)\n",
    "chunk_size = 1000\n",
    "\n",
    "def process_chunk(red_band, green_band):\n",
    "    try:\n",
    "        # Calculate vegetation indices for the chunk using float16\n",
    "        GI = np.divide(green_band.astype(np.float16), \n",
    "                       red_band.astype(np.float16), \n",
    "                       out=np.full_like(green_band, np.nan, dtype=np.float16), \n",
    "                       where=red_band != 0)\n",
    "        return GI\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process each .npy file in the directory\n",
    "for npy_file in os.listdir(output_folder):\n",
    "    npy_path = os.path.join(output_folder, npy_file)\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):\n",
    "        try:\n",
    "            # Print file path for debugging\n",
    "            print(f\"Processing file: {npy_path}\")\n",
    "            \n",
    "            # Load the NumPy array\n",
    "            full_img = np.load(npy_path)\n",
    "            \n",
    "            # Get image dimensions (ensure the array shape is correct)\n",
    "            _, height, width = full_img.shape\n",
    "            print(f\"Image dimensions: {height}x{width}\")\n",
    "            \n",
    "            # Prepare a list to hold the processed chunks\n",
    "            all_chunks = []\n",
    "\n",
    "            # Process the image in chunks\n",
    "            for y in range(0, height, chunk_size):\n",
    "                chunk_row = []  # Temporary list to hold chunks in the row\n",
    "                for x in range(0, width, chunk_size):\n",
    "                    # Define the chunk size\n",
    "                    end_y = min(y + chunk_size, height)\n",
    "                    end_x = min(x + chunk_size, width)\n",
    "\n",
    "                    # Extract bands for the chunk\n",
    "                    red_band = full_img[0, y:end_y, x:end_x].astype(np.float16)\n",
    "                    green_band = full_img[1, y:end_y, x:end_x].astype(np.float16)\n",
    "                    blue_band = full_img[2, y:end_y, x:end_x].astype(np.float16)\n",
    "\n",
    "                    # Process the chunk\n",
    "                    GI = process_chunk(red_band, green_band)\n",
    "                    if GI is not None:\n",
    "                        # Combine the processed chunk\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, GI])\n",
    "                        chunk_row.append(chunk_result)\n",
    "\n",
    "                # Concatenate chunks horizontally to form the row\n",
    "                if chunk_row:\n",
    "                    row_result = np.concatenate(chunk_row, axis=2)  # Concatenate along the width\n",
    "                    all_chunks.append(row_result)\n",
    "\n",
    "            # Concatenate all rows vertically to form the final image\n",
    "            if all_chunks:\n",
    "                updated_img = np.concatenate(all_chunks, axis=1)  # Concatenate along the height\n",
    "\n",
    "                # Output path for the updated image\n",
    "                output_filename = f'updated_{os.path.splitext(npy_file)[0]}.npy'\n",
    "                output_path = os.path.join(gi_index, output_filename)\n",
    "\n",
    "                # Save the modified image array as a new .npy file\n",
    "                np.save(output_path, updated_img)\n",
    "                print(f\"Processed and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{npy_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{npy_file}' as it's not a valid .npy file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795e0a9-850f-4ecf-9d3b-75dabedce130",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'H:\\Aerial_photos\\gi_index'  # Replace with your folder path\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            data = np.load(file_path)\n",
    "            print(f\"File '{filename}' loaded successfully\")\n",
    "            print(f\"Shape: {data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file '{filename}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9e8ad-cd67-4d8c-944b-901d22290a21",
   "metadata": {},
   "source": [
    "#### Red-Green Ratio Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcae763-799d-4376-bfcc-4d1a27786e65",
   "metadata": {},
   "execution_count": 4,
   "id": "fbcae763-799d-4376-bfcc-4d1a27786e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: H:\\Aerial_photographs\\gi_index\\updated_3129AA_01_2020_1386_RGB_RECT.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
      "Processing file: H:\\Aerial_photos\\gi_index\\updated_3128BB_05_2021_1384_RGB_RECT.npy\n",
      "Image dimensions: 23379x20301\n",
      "Processed and saved as H:\\Aerial_photos\\irg_index\\IRG_UPDATED_updated_3128BB_05_2021_1384_RGB_RECT.npy\n"
     ]
    }
   ],
   "source": [
    "# Define input and output folders\n",
    "gi_index = r'H:\\Aerial_photographs\\gi_index'  # Input folder containing .npy files\n",
    "irg_index = r'H:\\Aerial_photographs\\irg_index'  # Output folder for processed files\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "# Define output folder\n",
    "gi_index = r'H:\\Aerial_photos\\gi_index'\n",
    "irg_index = r'H:\\Aerial_photos\\irg_index'\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(irg_index, exist_ok=True)\n",
    "\n",
    "# Define chunk size \n",
    "chunk_size = 1000\n",
    "\n",
    "def process_chunk(red_band, green_band):\n",
    "    try:\n",
    "        # Calculate vegetation indices for the chunk\n",
    "        IRG = np.subtract(red_band, green_band).astype(np.float16)\n",
    "        return IRG\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process each .npy file in the directory\n",
    "for npy_file in os.listdir(gi_index):\n",
    "    npy_path = os.path.join(gi_index, npy_file)\n",
    "    \n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):\n",
    "for npy_file in os.listdir(gi_index):  # npy_file is just the filename as a string\n",
    "    npy_path = os.path.join(gi_index, npy_file)  # Full path to the file\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):  # Ensures only .npy files are processed\n",
    "        try:\n",
    "            # Print file path for debugging\n",
    "            print(f\"Processing file: {npy_path}\")\n",
    "            \n",
    "            # Load the NumPy array and convert to float16 for memory efficiency\n",
    "            full_img = np.load(npy_path).astype(np.float16)\n",
    "            \n",
    "            # Get image dimensions (ensure the array shape is correct)\n",
    "            _, height, width = full_img.shape\n",
    "            print(f\"Image dimensions: {height}x{width}\")\n",
    "            \n",
    "            # Prepare a list to hold the processed chunks\n",
    "            all_chunks = []\n",
    "            all_chunks = []  # Reset for each file\n",
    "\n",
    "            # Process the image in chunks\n",
    "            for y in range(0, height, chunk_size):\n",
    "                chunk_row = []  # Temporary list to hold chunks in the row\n",
    "                for x in range(0, width, chunk_size):\n",
    "                    # Define the chunk size\n",
    "                    end_y = min(y + chunk_size, height)\n",
    "                    end_x = min(x + chunk_size, width)\n",
    "\n",
    "                    # Extract bands for the chunk\n",
    "                    red_band = full_img[0, y:end_y, x:end_x]\n",
    "                    green_band = full_img[1, y:end_y, x:end_x]\n",
    "                    blue_band = full_img[2, y:end_y, x:end_x]\n",
    "                    gi_index_chunk = full_img[3, y:end_y, x:end_x]  # GI_Index band\n",
    "                    gi_index = full_img[3, y:end_y, x:end_x]  # GI_Index band\n",
    "\n",
    "                    # Process the chunk\n",
    "                    IRG = process_chunk(red_band, green_band)\n",
    "                    if IRG is not None:\n",
    "                        # Combine the processed chunk with the original bands\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index_chunk, IRG])\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index, IRG])\n",
    "                        chunk_row.append(chunk_result)\n",
    "\n",
    "                # Concatenate chunks horizontally to form the row\n",
    "                if chunk_row:\n",
    "                    row_result = np.concatenate(chunk_row, axis=2)  # Concatenate along the width\n",
    "                    all_chunks.append(row_result)\n",
    "\n",
    "            # Concatenate all rows vertically to form the final image\n",
    "            if all_chunks:\n",
    "                updated_img = np.concatenate(all_chunks, axis=1)  # Concatenate along the height\n",
    "\n",
    "                # Add the \"IRG_UPDATED_\" prefix to the filename\n",
    "                output_filename = f'IRG_UPDATED_{npy_file}'\n",
    "                output_path = os.path.join(irg_index, output_filename)\n",
    "\n",
    "                # Save the modified image array as a new .npy file\n",
    "                np.save(output_path, updated_img)\n",
    "                print(f\"Processed and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{npy_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{npy_file}' as it's not a valid .npy file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2dcc85-583f-4d18-8212-3d5fa8a17361",
   "metadata": {},
   "source": [
    "#### Normalized Green-Red Difference Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 10,
   "id": "0198d363-4d42-4230-a94d-2773a257e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: H:\\Aerial_photographs\\irg_index\\IRG_UPDATED_updated_3129AA_05_2020_1386_RGB_RECT.npy\n",
      "Processed and saved as H:\\Aerial_photographs\\ngrdi_index\\ngrdi_UPDATED_IRG_UPDATED_updated_3129AA_05_2020_1386_RGB_RECT.npy\n"
      "Processing file: H:\\Aerial_photos\\irg_index\\IRG_UPDATED_updated_3128BB_05_2021_1384_RGB_RECT.npy\n",
      "Image dimensions: 23379x20301\n",
      "Processed and saved as H:\\Aerial_photos\\ngrdi_index\\NGRDI_UPDATED_IRG_UPDATED_updated_3128BB_05_2021_1384_RGB_RECT.npy\n"
     ]
    }
   ],
   "source": [
    "# Define output folders\n",
    "irg_index = r'H:\\Aerial_photographs\\irg_index'  # Input folder with .npy files\n",
    "ngrdi_index = r'H:\\Aerial_photographs\\ngrdi_index'  # Output folder for processed files\n",
    "# Create the output folder if it doesn't exist\n",
    "# Define output folder\n",
    "irg_index = r'H:\\Aerial_photos\\irg_index'\n",
    "ngrdi_index = r'H:\\Aerial_photos\\ngrdi_index'\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(ngrdi_index, exist_ok=True)\n",
    "\n",
    "# Define chunk size \n",
    "chunk_size = 1000\n",
    "\n",
    "def process_chunk(red_band, green_band):\n",
    "    try:\n",
    "        # Calculate NGRDI for the chunk\n",
    "        NGRDI = np.divide((green_band - red_band),\n",
    "                          (green_band + red_band),\n",
    "        # Calculate vegetation indices for the chunk\n",
    "        # NGRDI (Green-Red)/(Green + Red)\n",
    "        NGRDI = np.divide((green_band - red_band),\n",
    "                          (green_band + red_band),\n",
    "                          out=np.full_like(green_band, np.nan, dtype=np.float16),\n",
    "                          where=(green_band + red_band) != 0)\n",
    "        return NGRDI\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process each .npy file in the directory\n",
    "for npy_file in os.listdir(irg_index):  \n",
    "    npy_path = os.path.join(irg_index, npy_file)  # Full path to the file\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):  \n",
    "for npy_file in os.listdir(irg_index):\n",
    "    npy_path = os.path.join(irg_index, npy_file)\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):\n",
    "        try:\n",
    "            # Print file path for debugging\n",
    "            print(f\"Processing file: {npy_path}\")\n",
    "            \n",
    "            # Load the NumPy array and convert to float16 for memory efficiency\n",
    "            full_img = np.load(npy_path).astype(np.float16)\n",
    "            \n",
    "            # Get image dimensions (ensure the array shape is correct)\n",
    "            _, height, width = full_img.shape\n",
    "            print(f\"Image dimensions: {height}x{width}\")\n",
    "            \n",
    "            # Prepare a list to hold the processed chunks\n",
    "            all_chunks = []  \n",
    "            all_chunks = []\n",
    "\n",
    "            # Process the image in chunks\n",
    "            for y in range(0, height, chunk_size):\n",
    "                chunk_row = []  # Temporary list to hold chunks in the row\n",
    "                for x in range(0, width, chunk_size):\n",
    "                    # Define the chunk size\n",
    "                    end_y = min(y + chunk_size, height)\n",
    "                    end_x = min(x + chunk_size, width)\n",
    "\n",
    "                    # Extract bands for the chunk\n",
    "                    red_band = full_img[0, y:end_y, x:end_x]\n",
    "                    green_band = full_img[1, y:end_y, x:end_x]\n",
    "                    blue_band = full_img[2, y:end_y, x:end_x]\n",
    "                    gi_index = full_img[3, y:end_y, x:end_x]  # GI_Index band\n",
    "                    irg_index = full_img[4, y:end_y, x:end_x]  # IRG_Index band\n",
    "\n",
    "                    # Process the chunk\n",
    "                    NGRDI = process_chunk(red_band, green_band)\n",
    "                    if NGRDI is not None:\n",
    "                        # Combine the processed chunk with the original bands\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index, NGRDI])\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index, irg_index, NGRDI])\n",
    "                        chunk_row.append(chunk_result)\n",
    "\n",
    "                # Concatenate chunks horizontally to form the row\n",
    "                if chunk_row:\n",
    "                    row_result = np.concatenate(chunk_row, axis=2)  # Concatenate along the width\n",
    "                    all_chunks.append(row_result)\n",
    "\n",
    "            # Concatenate all rows vertically to form the final image\n",
    "            if all_chunks:\n",
    "                updated_img = np.concatenate(all_chunks, axis=1)  # Concatenate along the height\n",
    "\n",
    "                # Add the \"ngrdi_UPDATED_\" prefix to the filename\n",
    "                output_filename = f'ngrdi_UPDATED_{npy_file}'\n",
    "                # Add the \"NGRDI_UPDATED_\" prefix to the filename\n",
    "                output_filename = f'NGRDI_UPDATED_{npy_file}'\n",
    "                output_path = os.path.join(ngrdi_index, output_filename)\n",
    "\n",
    "                # Save the modified image array as a new .npy file\n",
    "                np.save(output_path, updated_img)\n",
    "                print(f\"Processed and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{npy_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{npy_file}' as it's not a valid .npy file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2d436-e002-414e-b1b9-f6a300a6a088",
   "metadata": {},
   "source": [
    "#### Visable Atmospherically Resistant Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67521dca-6974-479f-8044-88eb706c85e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: H:\\Aerial_photographs\\ngrdi_index\\NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_01_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23379x20301\n",
      "Processed and saved as H:\\Aerial_photographs\\vari_index\\VARI_UPDATED_NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_01_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\ngrdi_index\\NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_02_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23387x20311\n",
      "Processed and saved as H:\\Aerial_photographs\\vari_index\\VARI_UPDATED_NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_02_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\ngrdi_index\\NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_03_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23396x20321\n",
      "Processed and saved as H:\\Aerial_photographs\\vari_index\\VARI_UPDATED_NGRDI_UPDATED_IRG_UPDATED_updated_3129AA_03_2020_1386_RGB_RECT.npy\n",
      "Processing file: H:\\Aerial_photographs\\ngrdi_index\\ngrdi_UPDATED_IRG_UPDATED_updated_3129AA_04_2020_1386_RGB_RECT.npy\n",
      "Image dimensions: 23405x20331\n",
      "Error processing 'ngrdi_UPDATED_IRG_UPDATED_updated_3129AA_04_2020_1386_RGB_RECT.npy': index 5 is out of bounds for axis 0 with size 5\n",
      "Processing file: H:\\Aerial_photographs\\ngrdi_index\\ngrdi_UPDATED_IRG_UPDATED_updated_3129AA_05_2020_1386_RGB_RECT.npy\n"
     ]
    }
   ],
   "source": [
    "# Define output folder\n",
    "ngrdi_index = r'H:\\Aerial_photographs\\ngrdi_index'\n",
    "\n",
    "vari_index = r'H:\\Aerial_photographs\\vari_index'\n",
   "outputs": [],
   "source": [
    "# Define output folder\n",
    "vari_index = r'H:\\Aerial_photos\\vari_index'\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(vari_index, exist_ok=True)\n",
    "\n",
    "# Define chunk size \n",
    "chunk_size = 1000\n",
    "\n",
    "def process_chunk(red_band, green_band, blue_band):\n",
    "    try:\n",
    "        # Calculate vegetation indices for the chunk\n",
    "        # VARI (Green-Red)/(Green+Red+Blue)\n",
    "        VARI = np.divide((green_band - red_band),\n",
    "                         (green_band + red_band + blue_band),\n",
    "                         out=np.full_like(green_band, np.nan, dtype=np.float16),\n",
    "                         where=(green_band + red_band + blue_band) != 0)\n",
    "        return VARI\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process each .npy file in the directory\n",
    "for npy_file in os.listdir(ngrdi_index):\n",
    "    npy_path = os.path.join(ngrdi_index, npy_file)\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):\n",
    "        try:\n",
    "            # Print file path for debugging\n",
    "            print(f\"Processing file: {npy_path}\")\n",
    "            \n",
    "            # Load the NumPy array and convert to float16 for memory efficiency\n",
    "            full_img = np.load(npy_path).astype(np.float16)\n",
    "            \n",
    "            # Get image dimensions (ensure the array shape is correct)\n",
    "            _, height, width = full_img.shape\n",
    "            print(f\"Image dimensions: {height}x{width}\")\n",
    "            \n",
    "            # Prepare a list to hold the processed chunks\n",
    "            all_chunks = []\n",
    "\n",
    "            # Process the image in chunks\n",
    "            for y in range(0, height, chunk_size):\n",
    "                chunk_row = []  # Temporary list to hold chunks in the row\n",
    "                for x in range(0, width, chunk_size):\n",
    "                    # Define the chunk size\n",
    "                    end_y = min(y + chunk_size, height)\n",
    "                    end_x = min(x + chunk_size, width)\n",
    "\n",
    "                    # Extract bands for the chunk\n",
    "                    red_band = full_img[0, y:end_y, x:end_x]\n",
    "                    green_band = full_img[1, y:end_y, x:end_x]\n",
    "                    blue_band = full_img[2, y:end_y, x:end_x]\n",
    "                    gi_index = full_img[3, y:end_y, x:end_x]  # GI_Index band\n",
    "                    irg_index = full_img[4, y:end_y, x:end_x]  # IRG_Index band\n",
    "                    NGRDI_index = full_img[5, y:end_y, x:end_x]  # NGRDI_Index band\n",
    "\n",
    "                    # Process the chunk\n",
    "                    VARI = process_chunk(red_band, green_band, blue_band)\n",
    "                    if VARI is not None:\n",
    "                        # Combine the processed chunk with the original bands\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index, irg_index, NGRDI_index, VARI])\n",
    "                        chunk_row.append(chunk_result)\n",
    "\n",
    "                # Concatenate chunks horizontally to form the row\n",
    "                if chunk_row:\n",
    "                    row_result = np.concatenate(chunk_row, axis=2)  # Concatenate along the width\n",
    "                    all_chunks.append(row_result)\n",
    "\n",
    "            # Concatenate all rows vertically to form the final image\n",
    "            if all_chunks:\n",
    "                updated_img = np.concatenate(all_chunks, axis=1)  # Concatenate along the height\n",
    "\n",
    "                # Add the \"VARI_UPDATED_\" prefix to the filename\n",
    "                output_filename = f'VARI_UPDATED_{npy_file}'\n",
    "                output_path = os.path.join(vari_index, output_filename)\n",
    "\n",
    "                # Save the modified image array as a new .npy file\n",
    "                np.save(output_path, updated_img)\n",
    "                print(f\"Processed and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{npy_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{npy_file}' as it's not a valid .npy file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2c3f0-42bb-473a-bfcf-1c5f6cb727b2",
   "metadata": {},
   "source": [
    "##### Visable Band Difference Vegetation Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc0427-7ad9-4f0b-b2fb-9bd43c3234c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output folder\n",
    "vdvi_index = r'H:\\Aerial_photographs\\vdvi_index'\n",
    "vdvi_index = r'H:\\Aerial_photos\\vdvi_index'\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(vdvi_index, exist_ok=True)\n",
    "\n",
    "# Define chunk size \n",
    "chunk_size = 1000\n",
    "\n",
    "def process_chunk(red_band, green_band, blue_band):\n",
    "    try:\n",
    "        # Calculate vegetation indices for the chunk\n",
    "        # VDVI (2* Green - Red - Blue) / (2* Green + Red + Blue)\n",
    "        VDVI = np.divide((2 * green_band - red_band - blue_band),\n",
    "                         (2 * green_band + red_band + blue_band),\n",
    "                         out=np.full_like(green_band, np.nan, dtype=np.float16),\n",
    "                         where=(2 * green_band + red_band + blue_band) != 0)\n",
    "    \n",
    "        return [VDVI]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process each .npy file in the directory\n",
    "for npy_file in os.listdir(vari_index):\n",
    "    npy_path = os.path.join(vari_index, npy_file)\n",
    "    if os.path.isfile(npy_path) and npy_file.endswith('.npy'):\n",
    "        try:\n",
    "            # Print file path for debugging\n",
    "            print(f\"Processing file: {npy_path}\")\n",
    "            \n",
    "            # Load the NumPy array and convert to float16 for memory efficiency\n",
    "            full_img = np.load(npy_path).astype(np.float16)\n",
    "            \n",
    "            # Get image dimensions (ensure the array shape is correct)\n",
    "            _, height, width = full_img.shape\n",
    "            print(f\"Image dimensions: {height}x{width}\")\n",
    "            \n",
    "            # Prepare a list to hold the processed chunks\n",
    "            all_chunks = []\n",
    "\n",
    "            # Process the image in chunks\n",
    "            for y in range(0, height, chunk_size):\n",
    "                chunk_row = []  # Temporary list to hold chunks in the row\n",
    "                for x in range(0, width, chunk_size):\n",
    "                    # Define the chunk size\n",
    "                    end_y = min(y + chunk_size, height)\n",
    "                    end_x = min(x + chunk_size, width)\n",
    "\n",
    "                    # Extract bands for the chunk\n",
    "                    red_band = full_img[0, y:end_y, x:end_x]\n",
    "                    green_band = full_img[1, y:end_y, x:end_x]\n",
    "                    blue_band = full_img[2, y:end_y, x:end_x]\n",
    "                    gi_index = full_img[3, y:end_y, x:end_x]  # GI_Index band\n",
    "                    irg_index = full_img[4, y:end_y, x:end_x]  # IRG_Index band\n",
    "                    ngrdi_index = full_img[5, y:end_y, x:end_x]  # NGRDI_Index band\n",
    "                    vari_index = full_img[6, y:end_y, x:end_x]  # VARI_Index band\n",
    "\n",
    "                    # Process the chunk\n",
    "                    results = process_chunk(red_band, green_band, blue_band)\n",
    "                    if results is not None:\n",
    "                        VDVI = results[0]\n",
    "                        # Combine the processed chunk with the original bands\n",
    "                        chunk_result = np.stack([red_band, green_band, blue_band, gi_index, irg_index, ngrdi_index, vari_index, VDVI])\n",
    "                        chunk_row.append(chunk_result)\n",
    "\n",
    "                # Concatenate chunks horizontally to form the row\n",
    "                if chunk_row:\n",
    "                    row_result = np.concatenate(chunk_row, axis=2)  # Concatenate along the width\n",
    "                    all_chunks.append(row_result)\n",
    "\n",
    "            # Concatenate all rows vertically to form the final image\n",
    "            if all_chunks:\n",
    "                updated_img = np.concatenate(all_chunks, axis=1)  # Concatenate along the height\n",
    "\n",
    "                # Add the \"VDVI_UPDATED_\" prefix to the filename\n",
    "                output_filename = f'VDVI_UPDATED_{npy_file}'\n",
    "                output_path = os.path.join(vdvi_index, output_filename)\n",
    "\n",
    "                # Save the modified image array as a new .npy file\n",
    "                np.save(output_path, updated_img)\n",
    "                print(f\"Processed and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{npy_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{npy_file}' as it's not a valid .npy file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671aac77-c3bc-4919-80b6-ad8f80e5fb51",
   "metadata": {},
   "source": [
    "### This cell prints out band numbers of each image to see if they were added as bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7e94f-117f-4a3f-9436-1e87b106c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files in the directory\n",
    "for file_name in os.listdir(vdvi_index):\n",
    "    file_path = os.path.join(vdvi_index, file_name)\n",
    "    \n",
    "    try:\n",
    "        # Load the .npy file\n",
    "        if file_name.lower().endswith('.npy'):\n",
    "            data = np.load(file_path)\n",
    "            print(f\"File '{file_name}' loaded successfully\")\n",
    "            print(f\"Shape of data: {data.shape}\")\n",
    "            \n",
    "            # Attempt to find associated metadata file\n",
    "            metadata_path = os.path.splitext(file_path)[0] + '_metadata.txt'\n",
    "            \n",
    "            if os.path.exists(metadata_path):\n",
    "                with open(metadata_path, 'r') as file:\n",
    "                    metadata = file.read()\n",
    "                    print(f\"Metadata for '{file_name}':\\n{metadata}\")\n",
    "            else:\n",
    "                print(f\"No metadata file found for '{file_name}'.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"'{file_name}' is not an .npy file, skipping.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file '{file_name}': {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
