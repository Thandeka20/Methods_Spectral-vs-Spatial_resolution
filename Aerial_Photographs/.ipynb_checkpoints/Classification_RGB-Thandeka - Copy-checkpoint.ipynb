{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baad9d88-d84a-4fae-9a4d-5dc70650ab94",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab815866-e19e-4290-be97-ed500dbb6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "import os\n",
    "import rasterio\n",
    "import fiona\n",
    "import json\n",
    "import csv\n",
    "from rasterio.merge import merge\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import Affine\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670472a7-78ff-40b8-adff-f1e72a6a514e",
   "metadata": {},
   "source": [
    "### This code loops through a folder to count the number of tiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e63f274-0f68-4962-96c0-08aabb8cf11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TIFF files found: 1\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the root folder\n",
    "root_folder = r'D:\\uMzi scene\\Test'\n",
    "\n",
    "# Initialize a counter for the number of TIFF files\n",
    "tif_count = 0\n",
    "\n",
    "# Iterate through all the directories and files in the root folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    # Iterate through the files in the current directory\n",
    "    for filename in filenames:\n",
    "        # Check if the file has a TIFF extension\n",
    "        if filename.endswith('.tif'):\n",
    "            # Increment the counter if it's a TIFF file\n",
    "            tif_count += 1\n",
    "\n",
    "# Print the total count of TIFF files found\n",
    "print(\"Total TIFF files found:\", tif_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb22820-ac96-44ce-a4d3-814843bc4035",
   "metadata": {},
   "source": [
    "### This code cell calculates and adds indices to each image in the folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00893fca-88d2-48a9-acab-dad0d1cc118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\uMzi scene\\Test\n",
      "D:\\uMzi scene\\Test\\updated_images\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the images\n",
    "images_dir = root_folder\n",
    "print(images_dir)\n",
    "\n",
    "# Create a folder to save the updated images if it doesn't exist\n",
    "output_folder = os.path.join(images_dir, 'updated_images')\n",
    "print(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448befc0-c24a-4245-8daf-19f17e4f8c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder 'dd':\n",
      "Skipping '3028DD_13_2020_1377_RGB_RECT.tfw' as it's not a valid TIFF file.\n",
      "Error processing '3028DD_13_2020_1377_RGB_RECT.tif': Unable to allocate 31.9 GiB for an array with shape (9, 23395, 20351) and data type float64\n",
      "Skipping '3028DD_13_2020_1377_RGB_RECT.tif.aux.xml' as it's not a valid TIFF file.\n",
      "Skipping '3028DD_13_2020_1377_RGB_RECT_METADATA.XML' as it's not a valid TIFF file.\n",
      "Skipping 'updated_images' as it's not a directory or it's the 'updated_images' folder.\n"
     ]
    }
   ],
   "source": [
    "# Define custom band names for the added indices\n",
    "band_names = ['GI', 'IRG', 'NGRDI', 'VARI', 'VDVI', 'WBI']\n",
    "\n",
    "# Loop through each folder in the directory\n",
    "for folder_name in os.listdir(images_dir):\n",
    "    folder_path = os.path.join(images_dir, folder_name)\n",
    "    \n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path) and folder_name != 'updated_images':  # Skip processing the 'updated_images' folder\n",
    "        print(f\"Processing folder '{folder_name}':\")\n",
    "        \n",
    "        # Loop through each image file in the folder\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            # Construct full path to the image file\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            \n",
    "            # Check if it's a file and if it ends with .tif or .TIF\n",
    "            if os.path.isfile(image_path) and (image_file.endswith('.tif') or image_file.endswith('.TIF')):\n",
    "                try:\n",
    "                    # Open the image\n",
    "                    with rasterio.open(image_path) as img:\n",
    "                        # Read all bands\n",
    "                        full_img = img.read()\n",
    "                       \n",
    "                        # Extract bands\n",
    "                        red_band = full_img[0, :, :]\n",
    "                        green_band = full_img[1, :, :]\n",
    "                        blue_band = full_img[2, :, :]\n",
    "\n",
    "                        # Calculate vegetation indices\n",
    "                        # 1) Greenness Index (GI) (Green/Red)\n",
    "                        GI = np.divide(green_band, red_band, out=np.zeros_like(green_band, dtype=float), where=red_band != 0)\n",
    "\n",
    "                        # 2) IRG (Red-Green)\n",
    "                        IRG = (red_band - green_band)\n",
    "\n",
    "                        # 3) NGRDI (Green-Red)/(Green + Red)\n",
    "                        NGRDI = np.divide((green_band - red_band),\n",
    "                                          (green_band + red_band),\n",
    "                                          where=(green_band + red_band) != 0)\n",
    "\n",
    "                        # 4) Calculate VARI (Green-Red)/(Green+Red+Blue)\n",
    "                        VARI = np.divide((green_band - red_band),\n",
    "                                         (green_band + red_band + blue_band),\n",
    "                                         out=np.zeros_like(green_band, dtype=float),  # Specify dtype=float\n",
    "                                         where=(green_band + red_band + blue_band) != 0)\n",
    "\n",
    "                        # 5) VDVI (2* Green-Red-Blue)/(2*Green+Red+Blue)\n",
    "                        VDVI = np.divide((2 * green_band - red_band - blue_band),\n",
    "                                         (2 * green_band + red_band + blue_band),\n",
    "                                         out=np.zeros_like(green_band, dtype=float),  # Specify dtype=float\n",
    "                                         where=(2 * green_band + red_band + blue_band) != 0)\n",
    "\n",
    "                        # 6) WBI (Blue-Red)/(Blue+Red)\n",
    "                        WBI = np.divide((blue_band - red_band),\n",
    "                                        (blue_band + red_band),\n",
    "                                        out=np.zeros_like(blue_band, dtype=float),  # Specify dtype=float\n",
    "                                        where=(blue_band + red_band) != 0)\n",
    "\n",
    "                        # Add the calculated indices as new bands to the image\n",
    "                        indices = [GI, IRG, NGRDI, VARI, VDVI, WBI]\n",
    "                        updated_img = np.concatenate((full_img, np.stack(indices)), axis=0)\n",
    "\n",
    "                        # Update band names in metadata profile\n",
    "                        profile = img.profile\n",
    "                        if 'descriptions' not in profile:\n",
    "                            profile['descriptions'] = [''] * img.count\n",
    "                        band_names_all = profile['descriptions'] + band_names\n",
    "                        profile.update(count=profile['count'] + len(indices), dtype='float16', descriptions=band_names_all)\n",
    "\n",
    "                        # Output path for the updated image\n",
    "                        output_filename = f'updated_{image_file}'\n",
    "                        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "                        # Write the modified image array to a new raster file\n",
    "                        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                            dst.write(updated_img.astype('float16'))  # Convert to float16 before writing\n",
    "\n",
    "                        print(f\"Indices added to the image and saved as {output_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing '{image_file}': {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping '{image_file}' as it's not a valid TIFF file.\")\n",
    "    else:\n",
    "        print(f\"Skipping '{folder_name}' as it's not a directory or it's the 'updated_images' folder.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f529e96-4677-4182-8823-599a1081d3d9",
   "metadata": {},
   "source": [
    "### This cell prints out band numbers of each image to see if they were added as bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7280d0ed-465c-4c6b-89e4-aa3470c26685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the updated images\n",
    "images_dir = r'D:\\uMzi scene\\Test\\updated_images'\n",
    "\n",
    "# Loop through each image in the directory\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith('.TIF') or image_file.endswith('.tif'):  # Check for both upper and lower case extensions\n",
    "       \n",
    "        # Open the image\n",
    "        with rasterio.open(os.path.join(images_dir, image_file)) as img:\n",
    "            # Print the number of bands\n",
    "            print(f\"Image '{image_file}' has {img.count} bands.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18aead-644d-4c9f-aec5-4a49aba876a3",
   "metadata": {},
   "source": [
    "### This code cell extracts pixel values from the images with the added VIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011e31b6-17e4-4cc1-8bf8-eb786824b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "pntsshp_path = r'D:\\From_Thas pc\\ValidationData\\RGB\\VAL.shp'\n",
    "\n",
    "image_dir = r'D:\\uMzi scene\\Test\\updated_images'\n",
    "\n",
    "# Get the first TIFF file from the directory\n",
    "tiff_files = [file for file in os.listdir(image_dir) if file.lower().endswith('.tif')]\n",
    "if not tiff_files:\n",
    "    raise FileNotFoundError(\"No TIFF files found in the specified directory.\")\n",
    "tiff_file = tiff_files[0]\n",
    "\n",
    "# Open shapefile and extract points' coordinates and attributes\n",
    "with fiona.open(pntsshp_path, 'r') as shapefile:\n",
    "    points = [[(point['geometry']['coordinates'][0], point['geometry']['coordinates'][1]),\n",
    "               (int(point['properties']['ID']), point['properties']['Val_id']),\n",
    "               (point['properties']['X'], point['properties']['Y'])] for point in shapefile]\n",
    "\n",
    "# Initialize dictionary to store band pixel values associated with each point\n",
    "point_pixel_values = {}\n",
    "\n",
    "# Process the TIFF file\n",
    "image_path = os.path.join(image_dir, tiff_file)\n",
    "with rasterio.open(image_path) as src:\n",
    "    imagename = os.path.splitext(os.path.basename(image_path))[0]  # Remove the file extension\n",
    "    \n",
    "    # Iterate over each band in the image\n",
    "    for band in range(1, src.count + 1):\n",
    "        # Iterate over each point and extract pixel values\n",
    "        for point in points:\n",
    "            row, col = src.index(point[0][0], point[0][1])  # Find the point within the raster image\n",
    "            values = src.read(band, window=((row, row + 1), (col, col + 1)))  # Read the band values\n",
    "\n",
    "            if values.size != 0:  # Check if bands are valid/not empty\n",
    "                # Prepare key for the current point\n",
    "                point_key = f\"Point_id: {point[1][1]}, X: {point[2][0]}, Y: {point[2][1]}, Class_ID: {point[1][0]}\"\n",
    "                if point_key not in point_pixel_values:\n",
    "                    point_pixel_values[point_key] = {}\n",
    "\n",
    "                # Add pixel values to the dictionary\n",
    "                point_pixel_values[point_key][f'{imagename}_Band_{band}'] = values[0][0]\n",
    "\n",
    "# Print point_pixel_values\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    print(f\"Point: {point_key}, Pixel Values: {pixel_values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae623de-1444-4afd-a71e-876405da85a9",
   "metadata": {},
   "source": [
    "### This cell changes point_pixel_value dictionary to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca85b90-9552-421f-91a9-7200d332609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "DataFrame successfully saved to C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\Imagery\\uMzimAOI\\SPOT6\\Band_values\\pixel_values.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries for DataFrame creation\n",
    "data_list = []\n",
    "\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    data_dict = {}\n",
    "    # Extracting Point ID, X, Y, and Class ID from point_key\n",
    "    point_id = point_key.split(',')[0].split(':')[1].strip()  \n",
    "    x_coord = point_key.split(',')[1].split(':')[1].strip()\n",
    "    y_coord = point_key.split(',')[2].split(':')[1].strip()\n",
    "    class_id = point_key.split(',')[3].split(':')[1].strip()\n",
    "    \n",
    "    # Add extracted information as separate columns\n",
    "    data_dict['Point'] = point_id\n",
    "    data_dict['X'] = x_coord\n",
    "    data_dict['Y'] = y_coord\n",
    "    data_dict['Class_ID'] = class_id\n",
    "    \n",
    "    # Add band pixel values as columns\n",
    "    data_dict.update(pixel_values)\n",
    "\n",
    "    data_list.append(data_dict)\n",
    "\n",
    "# Create DataFrame from list of dictionaries\n",
    "pixelvalues_df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame (optional)\n",
    "print(pixelvalues_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = r'D:\\uMzi scene\\Test\\Band_values\\pixel_values.csv'\n",
    "pixelvalues_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'DataFrame successfully saved to {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eca3be7-077c-43ab-8665-df6545875e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "#pixelvalues_df = pd.read_csv(r'E:\\SPOT6_7\\SPOT6_7\\BandValues\\pixel_values.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(pixelvalues_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78978c-ac1f-4ab4-aa08-375f10df2317",
   "metadata": {},
   "source": [
    "### This cell block trains the random forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f617d3-5261-46e2-82a0-fa053e3cf048",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['updated_SPOT6_clipped_Band_1', 'updated_SPOT6_clipped_Band_2',\\n       'updated_SPOT6_clipped_Band_3', 'updated_SPOT6_clipped_Band_4',\\n       'updated_SPOT6_clipped_Band_5', 'updated_SPOT6_clipped_Band_6',\\n       'updated_SPOT6_clipped_Band_7', 'updated_SPOT6_clipped_Band_8',\\n       'updated_SPOT6_clipped_Band_9', 'updated_SPOT6_clipped_Band_10'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define features \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m features \u001b[38;5;241m=\u001b[39m pixelvalues_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_9\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_SPOT6_clipped_Band_10\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define target (Class ID column)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m target \u001b[38;5;241m=\u001b[39m pixelvalues_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['updated_SPOT6_clipped_Band_1', 'updated_SPOT6_clipped_Band_2',\\n       'updated_SPOT6_clipped_Band_3', 'updated_SPOT6_clipped_Band_4',\\n       'updated_SPOT6_clipped_Band_5', 'updated_SPOT6_clipped_Band_6',\\n       'updated_SPOT6_clipped_Band_7', 'updated_SPOT6_clipped_Band_8',\\n       'updated_SPOT6_clipped_Band_9', 'updated_SPOT6_clipped_Band_10'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Define features \n",
    "features = pixelvalues_df[['updated_SPOT6_clipped_Band_1', 'updated_SPOT6_clipped_Band_2', 'updated_SPOT6_clipped_Band_3', 'updated_SPOT6_clipped_Band_4', 'updated_SPOT6_clipped_Band_5', 'updated_SPOT6_clipped_Band_6', 'updated_SPOT6_clipped_Band_7', 'updated_SPOT6_clipped_Band_8', 'updated_SPOT6_clipped_Band_9', 'updated_SPOT6_clipped_Band_10']]\n",
    "\n",
    "# Define target (Class ID column)\n",
    "target = pixelvalues_df['Class_ID']\n",
    "\n",
    "# Convert features and target columns to arrays\n",
    "features_array = features.values\n",
    "target_array = target.values\n",
    "\n",
    "# Train the classifier using RandomForest with 500 trees\n",
    "classifier = RandomForestClassifier(n_estimators=500)\n",
    "classifier.fit(features_array, target_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0227548-089c-415e-b592-542e23fcf25c",
   "metadata": {},
   "source": [
    "### This cell block performs the classification on each image in the folder using the trained classifer in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d2f23-6e3f-4b7a-b993-3d27d06b9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want to save the classified images\n",
    "output_folder = r\"D:\\uMzi scene\\Test\\Classified\"\n",
    "\n",
    "# Check if the output folder exists, if not, create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Define the directory containing the image\n",
    "image_dir = r'D:\\uMzi scene\\Test\\updated_images'\n",
    "umzim_boundary = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzimScene\\roi\\ROI.shp'\n",
    "\n",
    "# Find the single .tif or .TIF file in the directory\n",
    "image_path = None\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith('.tif'):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        break\n",
    "\n",
    "if not image_path:\n",
    "    raise FileNotFoundError(\"No .tif file found in the specified directory.\")\n",
    "\n",
    "# Read the ROI shapefile\n",
    "with fiona.open(umzim_boundary, 'r') as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "# Open the image using rasterio\n",
    "with rasterio.open(image_path) as src:\n",
    "    # Mask the image using the ROI shapefile\n",
    "    out_image, out_transform = mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"count\": src.count\n",
    "    })\n",
    "\n",
    "    # Get the shape of the masked image\n",
    "    rows, cols = out_image.shape[1], out_image.shape[2]\n",
    "\n",
    "    # Define batch size (adjust as needed based on memory constraints)\n",
    "    batch_size = 1000  # You can adjust this value\n",
    "\n",
    "    # Initialize the classification result array for the entire image\n",
    "    classification_result = np.zeros((rows, cols), dtype=np.uint8)\n",
    "\n",
    "    # Iterate over the image in batches\n",
    "    for row_start in range(0, rows, batch_size):\n",
    "        for col_start in range(0, cols, batch_size):\n",
    "            row_end = min(row_start + batch_size, rows)\n",
    "            col_end = min(col_start + batch_size, cols)\n",
    "\n",
    "            # Read the batch of bands\n",
    "            bands = [out_image[band_idx - 1, row_start:row_end, col_start:col_end] \n",
    "                     for band_idx in range(1, src.count + 1)]\n",
    "\n",
    "            # Stack the bands into a single array\n",
    "            stacked_bands = np.stack(bands, axis=-1)\n",
    "\n",
    "            # Reshape the array to 2D (rows, columns) for classification\n",
    "            reshaped_bands = stacked_bands.reshape(-1, src.count)\n",
    "\n",
    "            # Mask out no data values (pixels with a value of 0)\n",
    "            valid_pixels_mask = np.all(reshaped_bands != 0, axis=1)\n",
    "            valid_pixels = reshaped_bands[valid_pixels_mask]\n",
    "\n",
    "            if valid_pixels.size > 0:\n",
    "                # Predict using the trained classifier (replace this with your classifier)\n",
    "                predicted_labels = classifier.predict(valid_pixels)\n",
    "\n",
    "                # Create a temporary result array for this batch\n",
    "                batch_result = np.zeros((row_end - row_start, col_end - col_start), dtype=np.uint8)\n",
    "\n",
    "                # Fill in the valid pixels with the predicted labels\n",
    "                batch_result.reshape(-1)[valid_pixels_mask] = predicted_labels\n",
    "\n",
    "                # Write the batch result to the corresponding window in the full classification result array\n",
    "                classification_result[row_start:row_end, col_start:col_end] = batch_result\n",
    "\n",
    "    # Construct the output file path\n",
    "    output_filename = os.path.basename(image_path).replace('.tif', '_classified.tif')\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    # Prepare metadata for the classified image\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'uint8',  # Ensure data type is appropriate for classification results\n",
    "        'count': 1,  # Single band\n",
    "        'compress': 'lzw',  # Compression method (Lempel-Ziv-Welch)\n",
    "        'nodata': 0,  # Optional: Set nodata value\n",
    "        'crs': src.crs,  # Use the same CRS as the input raster\n",
    "        'transform': out_transform,  # Use the transform of the masked image\n",
    "    })\n",
    "\n",
    "    # Write the full classified image to a new GeoTIFF file\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        dst.write(classification_result.astype('uint8'), 1)\n",
    "\n",
    "print(\"Classification completed and classified image saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23c3be-1f14-4290-8fa2-f177d1fb539f",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5f59a-01f3-47e2-b3ed-560713b942cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define the paths\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "umzim_boundary = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\Fieldwork\\uMzimvubuFieldTrip\\uMzimvubuBoundary.shp'\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Check if there are any valid geometries\n",
    "        if not valid_points.empty and not valid_points.geometry.is_empty.all():\n",
    "            # Rasterize validation points onto classified image to extract pixel values\n",
    "            transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                    classified_image.res[0], classified_image.res[1])\n",
    "            rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                               out_shape=classified_image_data.shape,\n",
    "                                               transform=transform,\n",
    "                                               dtype='uint8')\n",
    "\n",
    "            # Extract pixel values from classified image corresponding to validation points\n",
    "            classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "            # Get ground truth labels corresponding to valid points\n",
    "            ground_truth_labels = valid_points['ID']\n",
    "\n",
    "            # Append to overall lists\n",
    "            all_ground_truth_labels.extend(ground_truth_labels)\n",
    "            all_classified_values.extend(classified_values)\n",
    "        else:\n",
    "            print(\"No valid geometries found for rasterization within the raster boundary.\")\n",
    "\n",
    "# Calculate overall accuracy metrics\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values)\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = np.unique(np.concatenate((all_ground_truth_labels, all_classified_values)))\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Specify the save location\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Overallaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a1fde-af29-49ed-b105-894802615afa",
   "metadata": {},
   "source": [
    "## Inter accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13b2ae-b47f-4403-a9e5-d7a401f8f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return 1  # Invasive alien class\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 2  # Non-invasive alien class\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Invasive Alien', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Interaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccbb52c-34db-4a66-81f8-27f4e173aef9",
   "metadata": {},
   "source": [
    "### Intra accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db87950-290c-4f1e-83b1-12b26854dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "classified_image_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\SPOT 6_7\\Classified_withIndices'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\Thand\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\Val_projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return class_id  # Keep individual classes 1 to 6\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 7  # Group classes 7 to 15 together as class 7\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Alien_Black Wattle', 'Alien_Gum', 'Alien_Other', 'Alien_Pine', 'Alien Poplar', 'Alien Silver Wattle', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Create a Pandas DataFrame for overall accuracy\n",
    "overall_accuracy_df = pd.DataFrame([overall_accuracy], columns=['Overall Accuracy'])\n",
    "\n",
    "# Specify the save location\n",
    "#output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Intraaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "#with pd.ExcelWriter(output_path) as writer:\n",
    "    #overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    #conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba63a1-2b36-4f0e-86e8-64b4681327d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
