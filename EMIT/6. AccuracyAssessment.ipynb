{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e325b69e-c500-4b12-9f9b-c9c9abbcec5f",
   "metadata": {},
   "source": [
    "# Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751ba5e-bd33-4298-899b-5794a8e60d18",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ffb7a-d14f-429e-ac9a-b4aa6da2d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "from rasterio.sample import sample_gen\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd642cd-1fd3-4bae-8981-4775092b85a1",
   "metadata": {},
   "source": [
    "#### Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2320e57a-6712-4bb1-8a33-5cbc686fbb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\Users\\User\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzi_ROI\\data\\EMIT\\13092014_emit\\classified\\emit_classified.tif\n",
      "Overall Accuracy: 0.9027777777777778\n",
      "Confusion Matrix:\n",
      "[[8 0 1 0 0 0 0 0]\n",
      " [0 6 2 0 0 1 0 0]\n",
      " [0 1 7 0 0 1 0 0]\n",
      " [0 0 0 9 0 0 0 0]\n",
      " [0 0 0 0 9 0 0 0]\n",
      " [0 0 0 0 0 9 0 0]\n",
      " [0 0 0 0 1 0 8 0]\n",
      " [0 0 0 0 0 0 0 9]]\n",
      "\n",
      "User's Accuracy:\n",
      "Class 1: 1.00\n",
      "Class 2: 0.86\n",
      "Class 3: 0.70\n",
      "Class 4: 1.00\n",
      "Class 5: 0.90\n",
      "Class 6: 0.82\n",
      "Class 7: 1.00\n",
      "Class 8: 1.00\n",
      "\n",
      "Producer's Accuracy:\n",
      "Class 1: 0.89\n",
      "Class 2: 0.67\n",
      "Class 3: 0.78\n",
      "Class 4: 1.00\n",
      "Class 5: 1.00\n",
      "Class 6: 1.00\n",
      "Class 7: 0.89\n",
      "Class 8: 1.00\n",
      "\n",
      "Kappa Coefficient:\n",
      "0.89\n",
      "\n",
      "Comparison Table:\n",
      "    Validation Value  Classified Value\n",
      "0                1.0               1.0\n",
      "1                6.0               6.0\n",
      "2                6.0               6.0\n",
      "3                1.0               1.0\n",
      "4                6.0               6.0\n",
      "..               ...               ...\n",
      "67               8.0               8.0\n",
      "68               5.0               5.0\n",
      "69               7.0               7.0\n",
      "70               8.0               8.0\n",
      "71               5.0               5.0\n",
      "\n",
      "[72 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the paths\n",
    "classified_image_path = r'C:\\Users\\User\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzi_ROI\\data\\EMIT\\13092014_emit\\classified'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\User\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzi_ROI\\Train_Val\\Validation_data\\validation_shapefile.shp'\n",
    "\n",
    "# Load validation shapefile as a geodataframe\n",
    "validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "\n",
    "# Initialize lists to store overall metrics\n",
    "all_validation_values = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Initialize lists to store detailed comparison data\n",
    "comparison_data = []\n",
    "\n",
    "# Loop through each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open the classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        # Generate samples of the classified image values at validation point locations\n",
    "        validation_values = []\n",
    "        classified_values = []\n",
    "        \n",
    "        for _, row in validation_gdf.iterrows():\n",
    "            coords = [(row.geometry.x, row.geometry.y)]\n",
    "            sampled_values = list(sample_gen(classified_image, coords))\n",
    "            if sampled_values:\n",
    "                classified_value = sampled_values[0][0]\n",
    "                validation_value = row['ID']  # Assuming 'ID' is the ground truth column name\n",
    "                classified_values.append(classified_value)\n",
    "                validation_values.append(validation_value)\n",
    "                \n",
    "                # Store comparison data\n",
    "                comparison_data.append({'Validation Value': validation_value, 'Classified Value': classified_value})\n",
    "        \n",
    "        # Append to overall lists\n",
    "        all_validation_values.extend(validation_values)\n",
    "        all_classified_values.extend(classified_values)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(all_validation_values, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_validation_values, all_classified_values)\n",
    "\n",
    "# Calculate User's and Producer's Accuracy\n",
    "def calculate_accuracy(conf_matrix):\n",
    "    total = np.sum(conf_matrix)\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    \n",
    "    user_accuracy = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    producer_accuracy = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    \n",
    "    return user_accuracy, producer_accuracy\n",
    "\n",
    "user_accuracy, producer_accuracy = calculate_accuracy(conf_matrix)\n",
    "\n",
    "# Calculate Kappa Coefficient\n",
    "def calculate_kappa(conf_matrix):\n",
    "    total = np.sum(conf_matrix)\n",
    "    sum_po = np.sum(np.diag(conf_matrix))\n",
    "    sum_pe = np.sum(np.sum(conf_matrix, axis=0) * np.sum(conf_matrix, axis=1)) / total\n",
    "    kappa = (sum_po - sum_pe) / (total - sum_pe)\n",
    "    return kappa\n",
    "\n",
    "kappa = calculate_kappa(conf_matrix)\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print User's Accuracy\n",
    "print(\"\\nUser's Accuracy:\")\n",
    "for i, acc in enumerate(user_accuracy):\n",
    "    print(f\"Class {i + 1}: {acc:.2f}\")\n",
    "\n",
    "# Print Producer's Accuracy\n",
    "print(\"\\nProducer's Accuracy:\")\n",
    "for i, acc in enumerate(producer_accuracy):\n",
    "    print(f\"Class {i + 1}: {acc:.2f}\")\n",
    "\n",
    "# Print Kappa Coefficient\n",
    "print(\"\\nKappa Coefficient:\")\n",
    "print(f\"{kappa:.2f}\")\n",
    "\n",
    "# Create and print comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d11021-e3fa-4c44-bbae-1aae6bc3207e",
   "metadata": {},
   "source": [
    "## Inter accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b33daa-cf56-4d13-85be-4b1a426b22cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\Users\\User\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzi_ROI\\data\\EMIT\\13092014_emit\\classified\\emit_classified.tif\n",
      "Overall Accuracy: 0.9722222222222222\n",
      "Confusion Matrix:\n",
      "[[25  2]\n",
      " [ 0 45]]\n",
      "\n",
      "Kappa Coefficient:\n",
      "0.94\n",
      "\n",
      "Comparison Table:\n",
      "    Validation Value  Classified Value Grouped Validation Grouped Classified\n",
      "0                1.0               1.0     Invasive Alien     Invasive Alien\n",
      "1                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "2                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "3                1.0               1.0     Invasive Alien     Invasive Alien\n",
      "4                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "..               ...               ...                ...                ...\n",
      "67               8.0               8.0       Non-Invasive       Non-Invasive\n",
      "68               5.0               5.0       Non-Invasive       Non-Invasive\n",
      "69               7.0               7.0       Non-Invasive       Non-Invasive\n",
      "70               8.0               8.0       Non-Invasive       Non-Invasive\n",
      "71               5.0               5.0       Non-Invasive       Non-Invasive\n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load validation shapefile as a geodataframe\n",
    "validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "\n",
    "# Initialize lists to store overall metrics\n",
    "all_validation_values = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Initialize lists to store detailed comparison data\n",
    "comparison_data = []\n",
    "\n",
    "# Define groups\n",
    "def group_class(value):\n",
    "    if value in [1, 2, 3]:  # Invasive alien plants\n",
    "        return 'Invasive Alien'\n",
    "    elif value in [4, 5, 6, 7, 8]:  # Non-invasive plants\n",
    "        return 'Non-Invasive'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Loop through each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open the classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        # Generate samples of the classified image values at validation point locations\n",
    "        validation_values = []\n",
    "        classified_values = []\n",
    "        \n",
    "        for _, row in validation_gdf.iterrows():\n",
    "            coords = [(row.geometry.x, row.geometry.y)]\n",
    "            sampled_values = list(sample_gen(classified_image, coords))\n",
    "            if sampled_values:\n",
    "                classified_value = sampled_values[0][0]\n",
    "                validation_value = row['ID']  # Assuming 'ID' is the ground truth column name\n",
    "                classified_values.append(classified_value)\n",
    "                validation_values.append(validation_value)\n",
    "                \n",
    "                # Store comparison data\n",
    "                comparison_data.append({\n",
    "                    'Validation Value': validation_value,\n",
    "                    'Classified Value': classified_value,\n",
    "                    'Grouped Validation': group_class(validation_value),\n",
    "                    'Grouped Classified': group_class(classified_value)\n",
    "                })\n",
    "        \n",
    "        # Append to overall lists\n",
    "        all_validation_values.extend(validation_values)\n",
    "        all_classified_values.extend(classified_values)\n",
    "\n",
    "# Group the values\n",
    "grouped_validation_values = [group_class(value) for value in all_validation_values]\n",
    "grouped_classified_values = [group_class(value) for value in all_classified_values]\n",
    "\n",
    "# Calculate overall accuracy for the grouped classes\n",
    "accuracy = accuracy_score(grouped_validation_values, grouped_classified_values)\n",
    "conf_matrix = confusion_matrix(grouped_validation_values, grouped_classified_values, labels=['Invasive Alien', 'Non-Invasive'])\n",
    "\n",
    "# Calculate Kappa Coefficient\n",
    "def calculate_kappa(conf_matrix):\n",
    "    total = np.sum(conf_matrix)\n",
    "    sum_po = np.sum(np.diag(conf_matrix))  # Observed agreement\n",
    "    sum_pe = np.sum(np.sum(conf_matrix, axis=0) * np.sum(conf_matrix, axis=1)) / total  # Expected agreement\n",
    "    kappa = (sum_po - sum_pe) / (total - sum_pe) if (total - sum_pe) != 0 else 0\n",
    "    return kappa\n",
    "\n",
    "kappa = calculate_kappa(conf_matrix)\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print Kappa Coefficient\n",
    "print(\"\\nKappa Coefficient:\")\n",
    "print(f\"{kappa:.2f}\")\n",
    "\n",
    "# Create and print comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa154d-8f2e-46a6-a110-19b74582d1c8",
   "metadata": {},
   "source": [
    "### Intra accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bca16af-fc04-44d4-9af3-b24c02413a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9166666666666666\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0]\n",
      " [ 0  6  2  1]\n",
      " [ 0  1  7  1]\n",
      " [ 0  0  0 45]]\n",
      "\n",
      "Kappa Coefficient:\n",
      "0.82\n",
      "\n",
      "Comparison Table:\n",
      "    Validation Value  Classified Value Grouped Validation Grouped Classified\n",
      "0                1.0               1.0    Invasive Alien     Invasive Alien \n",
      "1                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "2                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "3                1.0               1.0    Invasive Alien     Invasive Alien \n",
      "4                6.0               6.0       Non-Invasive       Non-Invasive\n",
      "..               ...               ...                ...                ...\n",
      "67               8.0               8.0       Non-Invasive       Non-Invasive\n",
      "68               5.0               5.0       Non-Invasive       Non-Invasive\n",
      "69               7.0               7.0       Non-Invasive       Non-Invasive\n",
      "70               8.0               8.0       Non-Invasive       Non-Invasive\n",
      "71               5.0               5.0       Non-Invasive       Non-Invasive\n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store overall metrics\n",
    "all_validation_values = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Initialize lists to store detailed comparison data\n",
    "comparison_data = []\n",
    "\n",
    "# Define groups\n",
    "def group_class(value):\n",
    "    if value == 1:  # Black Wattle\n",
    "        return 'Invasive Alien '  # Black Wattle\n",
    "    elif value == 2:  # Gum\n",
    "        return 'Invasive Alien 2'  # Gum\n",
    "    elif value == 3:  # Silver Wattle\n",
    "        return 'Invasive Alien 3'  # Silver Wattle\n",
    "    elif value in [4, 5, 6, 7, 8]:  # Non-invasive plants\n",
    "        return 'Non-Invasive'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "# Open the classified image\n",
    "with rasterio.open(classified_image_file) as classified_image:\n",
    "    # Generate samples of the classified image values at validation point locations\n",
    "    validation_values = []\n",
    "    classified_values = []\n",
    "    \n",
    "    for _, row in validation_gdf.iterrows():\n",
    "        coords = [(row.geometry.x, row.geometry.y)]\n",
    "        sampled_values = list(sample_gen(classified_image, coords))\n",
    "        if sampled_values:\n",
    "            classified_value = sampled_values[0][0]\n",
    "            validation_value = row['ID']  # Assuming 'ID' is the ground truth column name\n",
    "            classified_values.append(classified_value)\n",
    "            validation_values.append(validation_value)\n",
    "            \n",
    "            # Store comparison data\n",
    "            comparison_data.append({\n",
    "                'Validation Value': validation_value,\n",
    "                'Classified Value': classified_value,\n",
    "                'Grouped Validation': group_class(validation_value),\n",
    "                'Grouped Classified': group_class(classified_value)\n",
    "            })\n",
    "    \n",
    "    # Append to overall lists\n",
    "    all_validation_values.extend(validation_values)\n",
    "    all_classified_values.extend(classified_values)\n",
    "\n",
    "# Group the values\n",
    "grouped_validation_values = [group_class(value) for value in all_validation_values]\n",
    "grouped_classified_values = [group_class(value) for value in all_classified_values]\n",
    "\n",
    "# Calculate overall accuracy for the grouped classes\n",
    "accuracy = accuracy_score(grouped_validation_values, grouped_classified_values)\n",
    "conf_matrix = confusion_matrix(\n",
    "    grouped_validation_values,\n",
    "    grouped_classified_values,\n",
    "    labels=[\n",
    "        'Invasive Alien 1',  # Black Wattle\n",
    "        'Invasive Alien 2',  # Gum\n",
    "        'Invasive Alien 3',  # Silver Wattle\n",
    "        'Non-Invasive'       # Classes 4-8\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate Kappa Coefficient\n",
    "def calculate_kappa(conf_matrix):\n",
    "    total = np.sum(conf_matrix)\n",
    "    sum_po = np.sum(np.diag(conf_matrix))  # Observed agreement\n",
    "    sum_pe = np.sum(np.sum(conf_matrix, axis=0) * np.sum(conf_matrix, axis=1)) / total  # Expected agreement\n",
    "    kappa = (sum_po - sum_pe) / (total - sum_pe) if (total - sum_pe) != 0 else 0\n",
    "    return kappa\n",
    "\n",
    "kappa = calculate_kappa(conf_matrix)\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print Kappa Coefficient\n",
    "print(\"\\nKappa Coefficient:\")\n",
    "print(f\"{kappa:.2f}\")\n",
    "\n",
    "# Create and print comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
