{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e436cc34-3978-485c-95e3-5e22bf5a9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import argparse\n",
    "import os\n",
    "#import geoviews\n",
    "import warnings\n",
    "import rasterio as rio\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import mapping, box\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.mask import mask\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02e52c1-6b49-4ef7-bb4e-e63deab19aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"fa96d957-6d4c-4354-96d5-897094256b7d\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"73419a79-0ecf-4ec7-83df-238839142ff4\":{\"version\":\"3.4.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"247d50e0a77b4e5d8b37de2b6c4b08cd\",\"client_comm_id\":\"ca1c638a8ccb45329b0cc371bbce6c29\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"73419a79-0ecf-4ec7-83df-238839142ff4\",\"roots\":{\"p1002\":\"fa96d957-6d4c-4354-96d5-897094256b7d\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from osgeo import gdal\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import rasterio as rio\n",
    "#from modules.emit_tools import emit_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4683b606-d1e0-42e8-a0bf-f0f84be52548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 'clipped' as it's not a valid TIFF file.\n",
      "Image clipped and saved as E:\\uMzi scene\\data\\EMIT\\clipped\\clipped_EMIT_L2A_TIF_001_20240229T101944_2406007_016.tif\n",
      "Skipping 'Updated_indicies' as it's not a valid TIFF file.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the TIFF images\n",
    "images_dir = r'E:\\uMzi scene\\data\\EMIT'\n",
    "\n",
    "roi_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\uMzimScene\\roi\\ROI.shp'\n",
    "\n",
    "# Create a folder to save the clipped images if it doesn't exist\n",
    "clipped_folder = r'E:\\uMzi scene\\data\\EMIT\\clipped'\n",
    "if not os.path.exists(clipped_folder):\n",
    "    os.makedirs(clipped_folder)\n",
    "\n",
    "# Load ROI shapefile\n",
    "roi = gpd.read_file(roi_path)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for image_file in os.listdir(images_dir):\n",
    "    # Construct full path to the image file\n",
    "    image_path = os.path.join(images_dir, image_file)\n",
    "    \n",
    "    # Check if it's a file and if it ends with .tif or .TIF\n",
    "    if os.path.isfile(image_path) and (image_file.endswith('.tif') or image_file.endswith('.TIF')):\n",
    "        try:\n",
    "            # Open the image\n",
    "            with rasterio.open(image_path) as img:\n",
    "                # Clip the image using the ROI\n",
    "                clipped_img, clipped_transform = mask(img, roi.geometry, crop=True)\n",
    "                \n",
    "                # Update metadata profile for the clipped image\n",
    "                profile = img.profile\n",
    "                profile.update({\n",
    "                    'height': clipped_img.shape[1],\n",
    "                    'width': clipped_img.shape[2],\n",
    "                    'transform': clipped_transform\n",
    "                })\n",
    "\n",
    "                # Output path for the clipped image\n",
    "                clipped_filename = f'clipped_{image_file}'\n",
    "                clipped_path = os.path.join(clipped_folder, clipped_filename)\n",
    "\n",
    "                # Write the clipped image to a new raster file\n",
    "                with rasterio.open(clipped_path, 'w', **profile) as dst:\n",
    "                    dst.write(clipped_img)\n",
    "\n",
    "                print(f\"Image clipped and saved as {clipped_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{image_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{image_file}' as it's not a valid TIFF file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a68e41-4c6b-4cff-86ee-a1d6fef56e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 'clipped_EMIT_L2A_TIF_001_20240229T101944_2406007_016.tif': Attempt to create new tiff file 'E:/Imagery/EMIT/UpdatedIndices/updated_clipped_EMIT_L2A_TIF_001_20240229T101944_2406007_016.tif' failed: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to save the updated images if it doesn't exist\n",
    "output_folder = r'E:\\Imagery\\EMIT\\UpdatedIndices'\n",
    "\n",
    "# Define custom band names for the added indices\n",
    "band_names = ['GI', 'IRG', 'NGRDI', 'VARI', 'VDVI', 'WBI']\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for image_file in os.listdir(clipped_folder):\n",
    "    # Construct full path to the image file\n",
    "    image_path = os.path.join(clipped_folder, image_file)\n",
    "    \n",
    "    # Check if it's a file and if it ends with .tif or .TIF\n",
    "    if os.path.isfile(image_path) and (image_file.endswith('.tif') or image_file.endswith('.TIF')):\n",
    "        try:\n",
    "            # Open the image\n",
    "            with rasterio.open(image_path) as img:\n",
    "                # Read all bands\n",
    "                full_img = img.read()\n",
    "               \n",
    "                # Extract bands\n",
    "                red_band = full_img[0, :, :]\n",
    "                green_band = full_img[1, :, :]\n",
    "                blue_band = full_img[2, :, :]\n",
    "\n",
    "                # Calculate vegetation indices\n",
    "                # 1) Greenness Index (GI) (Green/Red)\n",
    "                GI = np.divide(green_band, red_band, out=np.zeros_like(green_band, dtype=float), where=red_band != 0)\n",
    "\n",
    "                # 2) IRG (Red-Green)\n",
    "                IRG = (red_band - green_band)\n",
    "\n",
    "                # 3) NGRDI (Green-Red)/(Green + Red)\n",
    "                NGRDI = np.divide((green_band - red_band),\n",
    "                                  (green_band + red_band),\n",
    "                                  where=(green_band + red_band) != 0)\n",
    "\n",
    "                # 4) Calculate VARI (Green-Red)/(Green+Red+Blue)\n",
    "                VARI = np.divide((green_band - red_band),\n",
    "                                 (green_band + red_band + blue_band),\n",
    "                                 out=np.zeros_like(green_band, dtype=float),  # Specify dtype=float\n",
    "                                 where=(green_band + red_band + blue_band) != 0)\n",
    "\n",
    "                # 5) VDVI (2* Green-Red-Blue)/(2*Green+Red+Blue)\n",
    "                VDVI = np.divide((2 * green_band - red_band - blue_band),\n",
    "                                 (2 * green_band + red_band + blue_band),\n",
    "                                 out=np.zeros_like(green_band, dtype=float),  # Specify dtype=float\n",
    "                                 where=(2 * green_band + red_band + blue_band) != 0)\n",
    "\n",
    "                # 6) WBI (Blue-Red)/(Blue+Red)\n",
    "                WBI = np.divide((blue_band - red_band),\n",
    "                                (blue_band + red_band),\n",
    "                                out=np.zeros_like(blue_band, dtype=float),  # Specify dtype=float\n",
    "                                where=(blue_band + red_band) != 0)\n",
    "\n",
    "                # Add the calculated indices as new bands to the image\n",
    "                indices = [GI, IRG, NGRDI, VARI, VDVI, WBI]\n",
    "                updated_img = np.concatenate((full_img, np.stack(indices)), axis=0)\n",
    "\n",
    "                # Update band names in metadata profile\n",
    "                profile = img.profile\n",
    "                if 'descriptions' not in profile:\n",
    "                    profile['descriptions'] = [''] * img.count\n",
    "                band_names_all = profile['descriptions'] + band_names\n",
    "                profile.update(count=profile['count'] + len(indices), dtype='float32', descriptions=band_names_all)\n",
    "\n",
    "                # Output path for the updated image\n",
    "                output_filename = f'updated_{image_file}'\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "                # Write the modified image array to a new raster file\n",
    "                with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                    dst.write(updated_img.astype('float32'))  # Convert to float32 before writing\n",
    "\n",
    "                print(f\"Indices added to the image and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{image_file}': {e}\")\n",
    "    else:\n",
    "        print(f\"Skipping '{image_file}' as it's not a valid TIFF file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c38101-496c-4707-a3a8-2c32dfe23609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 'updated_EMIT_L2A_RFL_001_20240229T101944_2406007_016.tif' has 291 bands.\n",
      "Image 'updated_EMIT_L2A_RFL_001_20240304T084440_2406406_015.tif' has 291 bands.\n",
      "Image 'updated_EMIT_L2A_RFL_001_20240308T070913_2406805_011.tif' has 291 bands.\n",
      "Image 'updated_EMIT_L2A_RFL_001_20240324T090114_2408405_022.tif' has 291 bands.\n",
      "Image 'updated_EMIT_L2A_RFL_001_20240308T070902_2406805_010.tif' has 291 bands.\n",
      "Image 'updated_EMIT_L2A_RFL_001_20240312T134306_2407208_010.tif' has 291 bands.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the updated images\n",
    "images_dir = r'F:\\Imagery\\EMIT\\UpdatedIndices'\n",
    "\n",
    "# Loop through each image in the directory\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith('.TIF') or image_file.endswith('.tif'):  # Check for both upper and lower case extensions\n",
    "       \n",
    "        # Open the image\n",
    "        with rasterio.open(os.path.join(images_dir, image_file)) as img:\n",
    "            # Print the number of bands\n",
    "            print(f\"Image '{image_file}' has {img.count} bands.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a482e7e-d607-49bf-b87c-927e76210c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "pntsshp_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\TrainingData\\Emit_projected\\TrainingData.shp'\n",
    "imagesdir = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Code Test\\Imagery\\EMIT\\uMzimvubu\\s4\\updated'\n",
    "\n",
    "# Get file path list of all TIFF images in dir\n",
    "imagelist = [os.path.join(imagesdir, file) for file in os.listdir(imagesdir) if file.endswith('.tif')]\n",
    "#print(imagelist)\n",
    "\n",
    "# Initialize dictionaries\n",
    "imgvals = {}\n",
    "\n",
    "# Open shapefile and extract points' coordinates [0]= x coordinate, [1]= y coordinate  and attributes\n",
    "with fiona.open(pntsshp_path, 'r') as shapefile:\n",
    "    points = [[(point['geometry']['coordinates'][0], point['geometry']['coordinates'][1]),\n",
    "               (int(point['properties']['ID']), point['properties']['Val_id']),\n",
    "               (point['properties']['X'], point['properties']['Y'])] for point in shapefile]\n",
    "    #for point in shapefile:\n",
    "        #print(point['properties']['ID'])\n",
    "\n",
    "        #print(point['properties']['ID'])\n",
    "\n",
    "# Initialize dictionary to store band pixel values associated with each point\n",
    "point_pixel_values = {}\n",
    "\n",
    "# Iterate over each raster image\n",
    "for imagepath in imagelist:\n",
    "    with rasterio.open(imagepath) as src:\n",
    "        \n",
    "        # Initialize dictionaries for current image\n",
    "        imagename = os.path.splitext(os.path.basename(imagepath))[0] #splittext removes the extension from files.\n",
    "        \n",
    "        # Iterate over each band\n",
    "        for band in range(1, src.count + 1):\n",
    "            \n",
    "            # Initialize dictionary for current band\n",
    "            band_pixel_values = {}\n",
    "\n",
    "            # Iterate over each point and extract pixel values\n",
    "            for point in points:\n",
    "                row, col = src.index(point[0][0], point[0][1]) # Find the point within the raster image\n",
    "                values = src.read(band, window=((row, row+1), (col, col+1))) # Read the band values \n",
    "               \n",
    "\n",
    "                if values.size != 0: # Check if bands are valid/not empty\n",
    "                    # Populate band_pixel_values dictionary\n",
    "                    band_pixel_values[f'Band_{band}'] = values[0][0]\n",
    "                    \n",
    "                    # Add band_pixel_values to point_pixel_values for the current point\n",
    "                    point_key = str(\"Point_id: {}, X: {}, Y: {}, Class_ID: {}\".format(point[1][1], point[2][0], point[2][1], point[1][0] ))\n",
    "                    if point_key not in point_pixel_values:\n",
    "                        point_pixel_values[point_key] = {}\n",
    "                    point_pixel_values[point_key].update(band_pixel_values)\n",
    "                   \n",
    "                         \n",
    "# Print point_pixel_values\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    print(f\"Point: {point_key}, Pixel Values: {pixel_values}, Image name: {imagename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c048e1f8-9683-48cf-bdbf-5d2f85b864b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Point              X               Y Class_ID    Band_1    Band_2  \\\n",
      "0        VAL_0  28.8670583068   -31.416997845       12       NaN       NaN   \n",
      "1        VAL_1  28.8782059946  -31.4220682292        2       NaN       NaN   \n",
      "2        VAL_3  28.8980250693  -31.4243007231        1       NaN       NaN   \n",
      "3        VAL_4  28.8984465501  -31.4243855716        1       NaN       NaN   \n",
      "4        VAL_5  28.8981179473  -31.4236682596        1       NaN       NaN   \n",
      "...        ...            ...             ...      ...       ...       ...   \n",
      "3369  VAL_4543  29.5387540916  -30.5418692849        5  0.015632  0.016315   \n",
      "3370  VAL_3628  29.2683040189  -29.9892013295       14       NaN       NaN   \n",
      "3371  VAL_3629  29.2691195163  -29.9841363872       14       NaN       NaN   \n",
      "3372  VAL_3630  29.2574755009  -29.9868643158       14  0.011069  0.010519   \n",
      "3373  VAL_3631  29.2412399673  -29.9609801189       14       NaN       NaN   \n",
      "\n",
      "        Band_3    Band_4    Band_5    Band_6  ...  Band_282  Band_283  \\\n",
      "0          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "1          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "2          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "3          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "4          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
      "...        ...       ...       ...       ...  ...       ...       ...   \n",
      "3369  0.016998  0.017684  0.018513  0.019573  ...  0.045662  0.044733   \n",
      "3370       NaN       NaN       NaN       NaN  ...  0.000000  0.000000   \n",
      "3371       NaN       NaN       NaN       NaN  ...  0.000000  0.000000   \n",
      "3372  0.009976  0.009433  0.009320  0.009577  ...  0.000000  0.000000   \n",
      "3373       NaN       NaN       NaN       NaN  ...  0.000000  0.000000   \n",
      "\n",
      "      Band_284  Band_285  Band_286  Band_287  Band_288  Band_289  Band_290  \\\n",
      "0          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "3          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "4          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "3369  0.043189  0.041934  1.043681 -0.000683  0.021374  0.013951  0.000002   \n",
      "3370  0.000000  0.000000       NaN       NaN       NaN       NaN       NaN   \n",
      "3371  0.000000  0.000000       NaN       NaN       NaN       NaN       NaN   \n",
      "3372  0.000000  0.000000  0.950247  0.000551 -0.025511 -0.017448 -0.000197   \n",
      "3373  0.000000  0.000000       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "      Band_291  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "...        ...  \n",
      "3369  0.041849  \n",
      "3370       NaN  \n",
      "3371       NaN  \n",
      "3372 -0.051942  \n",
      "3373       NaN  \n",
      "\n",
      "[3374 rows x 295 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries for DataFrame creation\n",
    "data_list = []\n",
    "\n",
    "for point_key, pixel_values in point_pixel_values.items():\n",
    "    data_dict = {}\n",
    "    # Extracting Point ID, X, Y, and Class ID from point_key\n",
    "    point_id = point_key.split(',')[0].split(':')[1].strip()  \n",
    "    x_coord = point_key.split(',')[1].split(':')[1].strip()\n",
    "    y_coord = point_key.split(',')[2].split(':')[1].strip()\n",
    "    class_id = point_key.split(',')[3].split(':')[1].strip()\n",
    "    \n",
    "    # Add extracted information as separate columns\n",
    "    data_dict['Point'] = point_id\n",
    "    data_dict['X'] = x_coord\n",
    "    data_dict['Y'] = y_coord\n",
    "    data_dict['Class_ID'] = class_id\n",
    "    \n",
    "    # Add band pixel values as columns\n",
    "    data_dict.update(pixel_values)\n",
    "\n",
    "    data_list.append(data_dict)\n",
    "\n",
    "# Create DataFrame from list of dictionaries\n",
    "pixelvalues_df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(pixelvalues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0740be99-0482-4874-a034-4f678148656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features \n",
    "# Find the index of the last non-band column\n",
    "last_non_band_index = pixelvalues_df.columns.tolist().index('Class_ID')  # Replace 'Last_Non_Band_Column' with the name of your last non-band column\n",
    "\n",
    "# Select columns starting from the column following the last non-band column\n",
    "features = pixelvalues_df.iloc[:, last_non_band_index + 1:]\n",
    "#print(features)\n",
    "\n",
    "# Define target (Class ID column)\n",
    "target = pixelvalues_df['Class_ID']\n",
    "\n",
    "# Convert features and target columns to arrays\n",
    "features_array = features.values\n",
    "target_array = target.values\n",
    "\n",
    "# Train the classifier using RandomForest with 500 trees\n",
    "classifier = RandomForestClassifier(n_estimators=500)\n",
    "classifier.fit(features_array, target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813d7e97-2759-43ff-848e-d6b085c46fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 291)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m valid_pixels \u001b[38;5;241m=\u001b[39m reshaped_bands[valid_pixels_mask]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Predict using the trained classifier\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(valid_pixels)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Create an array to store the classification results\u001b[39;00m\n\u001b[0;32m     32\u001b[0m classification_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(rows \u001b[38;5;241m*\u001b[39m cols, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    885\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    945\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    950\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SPOT\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 291)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the classified images\n",
    "output_folder = r\"F:\\Classified\"\n",
    "\n",
    "# Check if the output folder exists, if not, create it\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each image in the collection\n",
    "for image_path in imagelist:\n",
    "    \n",
    "    # Open the image using rasterio\n",
    "    with rasterio.open(image_path) as src:\n",
    "        \n",
    "        # Read the bands in the images\n",
    "        bands = [src.read(band_idx) for band_idx in range(1, src.count + 1)]  # Read all bands\n",
    "        \n",
    "        # Stack the bands into a single array\n",
    "        stacked_bands = np.stack(bands, axis=-1)\n",
    "        \n",
    "        # Reshape the array to 2D (rows, columns) for classification\n",
    "        rows, cols, num_bands = stacked_bands.shape\n",
    "        reshaped_bands = stacked_bands.reshape(rows * cols, num_bands)\n",
    "        \n",
    "        # Mask out no data values (pixels with NaN values)\n",
    "        valid_pixels_mask = np.all(~np.isnan(reshaped_bands), axis=1)\n",
    "        valid_pixels = reshaped_bands[valid_pixels_mask]\n",
    "        \n",
    "        # Predict using the trained classifier\n",
    "        predicted_labels = classifier.predict(valid_pixels)\n",
    "        \n",
    "        # Create an array to store the classification results\n",
    "        classification_result = np.full(rows * cols, fill_value=np.nan, dtype=np.float32)\n",
    "        \n",
    "        # Fill in the valid pixels with the predicted labels\n",
    "        classification_result[valid_pixels_mask] = predicted_labels\n",
    "        \n",
    "        # Reshape the classified result back to 2D\n",
    "        classification_result_2d = classification_result.reshape(rows, cols)\n",
    "        \n",
    "        # Construct the output file path\n",
    "        output_filename = os.path.basename(image_path).replace('.tif', '_classified.tif')\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        # Prepare metadata for the classified image\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'driver': 'GTiff',\n",
    "            'dtype': 'float32',  # Use float32 to accommodate NaN values\n",
    "            'count': 1,  # Single band\n",
    "            'compress': 'lzw',  # Compression method (Lempel-Ziv-Welch)\n",
    "            'nodata': np.nan,  # Set nodata value to NaN\n",
    "            'crs': src.crs,  # Use the same CRS as the input raster\n",
    "            'transform': src.transform,  # Use the same transform as the input raster\n",
    "        })\n",
    "        \n",
    "        # Write the classified image to a new GeoTIFF file\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(classification_result_2d, 1)\n",
    "\n",
    "print(\"Classification completed and classified images saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fcd45-ad04-4cc5-b74b-98d3892f125b",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120583c1-4ee7-4e98-b905-78db036791fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "classified_image_path = r'F:\\Classified'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\ValSet_EMIT_PROJECT\\ValSet_Projected.shp'\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(ground_truth_labels)\n",
    "        all_classified_values.extend(classified_values)\n",
    "\n",
    "# Calculate overall accuracy metrics\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values)\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = np.unique(np.concatenate((all_ground_truth_labels, all_classified_values)))\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Write the results to an Excel file\n",
    "# Specify the save location\n",
    "output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Overallaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0b981-c6b0-4691-9379-ad9e2ae09dc1",
   "metadata": {},
   "source": [
    "### Inter accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b27c85-e49e-44b5-b0a9-f96aff5dfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "\n",
    "classified_image_path = r'F:\\Classified'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\ValSet_EMIT_PROJECT\\ValSet_Projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return 1  # Invasive alien class\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 2  # Non-invasive alien class\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Invasive Alien', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Write the results to an Excel file\n",
    "output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Interaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e718a0-67f8-487b-bc5e-fcab8c7000e6",
   "metadata": {},
   "source": [
    "### Intra accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47aa542-7e68-4a77-86bf-3c1b24c71ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "classified_image_path = r'F:\\Classified'\n",
    "classified_imagelist = [os.path.join(classified_image_path, file) for file in os.listdir(classified_image_path) if file.endswith('.TIF') or file.endswith('.tif')]\n",
    "\n",
    "validation_shapefile_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Data\\ValidationData\\ValSet_EMIT_PROJECT\\ValSet_Projected.shp'\n",
    "\n",
    "\n",
    "# Initialize variables to store overall metrics\n",
    "all_ground_truth_labels = []\n",
    "all_classified_values = []\n",
    "\n",
    "# Mapping function to aggregate classes\n",
    "def aggregate_class(class_id):\n",
    "    if 1 <= class_id <= 6:\n",
    "        return class_id  # Keep individual classes 1 to 6\n",
    "    elif 7 <= class_id <= 15:\n",
    "        return 7  # Group classes 7 to 15 together as class 7\n",
    "    else:\n",
    "        return 0  # Undefined class (if any other IDs are present)\n",
    "\n",
    "# Loop over each classified image\n",
    "for classified_image_file in classified_imagelist:\n",
    "    print(\"Processing:\", classified_image_file)\n",
    "    \n",
    "    # Open classified image\n",
    "    with rasterio.open(classified_image_file) as classified_image:\n",
    "        \n",
    "        # Read classified image\n",
    "        classified_image_data = classified_image.read(1)\n",
    "\n",
    "        # Load validation shapefile as a geodataframe\n",
    "        validation_gdf = gpd.read_file(validation_shapefile_path)\n",
    "        \n",
    "        # Filter validation points falling within the raster boundary\n",
    "        raster_boundary = classified_image.bounds\n",
    "        valid_points = validation_gdf.cx[raster_boundary.left:raster_boundary.right, \n",
    "                                         raster_boundary.bottom:raster_boundary.top]\n",
    "\n",
    "        # Rasterize validation points onto classified image to extract pixel values\n",
    "        transform = from_origin(classified_image.bounds.left, classified_image.bounds.top,\n",
    "                                classified_image.res[0], classified_image.res[1])\n",
    "        rasterized_validation = rasterize([(geom, 1) for geom in valid_points.geometry],\n",
    "                                           out_shape=classified_image_data.shape,\n",
    "                                           transform=transform,\n",
    "                                           dtype='uint8')\n",
    "\n",
    "        # Extract pixel values from classified image corresponding to validation points\n",
    "        classified_values = classified_image_data[rasterized_validation == 1]\n",
    "\n",
    "        # Get ground truth labels corresponding to valid points\n",
    "        ground_truth_labels = valid_points['ID']\n",
    "\n",
    "        # Map ground truth and classified values to aggregated classes\n",
    "        ground_truth_labels_aggregated = [aggregate_class(label) for label in ground_truth_labels]\n",
    "        classified_values_aggregated = [aggregate_class(value) for value in classified_values]\n",
    "\n",
    "        # Filter out undefined classes (if any)\n",
    "        filtered_ground_truth = [gt for gt in ground_truth_labels_aggregated if gt != 0]\n",
    "        filtered_classified = [cl for gt, cl in zip(ground_truth_labels_aggregated, classified_values_aggregated) if gt != 0]\n",
    "\n",
    "        # Append to overall lists\n",
    "        all_ground_truth_labels.extend(filtered_ground_truth)\n",
    "        all_classified_values.extend(filtered_classified)\n",
    "\n",
    "# Calculate overall accuracy metrics for aggregated classes\n",
    "overall_accuracy = accuracy_score(all_ground_truth_labels, all_classified_values)\n",
    "conf_matrix = confusion_matrix(all_ground_truth_labels, all_classified_values, labels=[1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Convert the confusion matrix to a pandas DataFrame for formatting\n",
    "class_names = ['Alien_Black Wattle', 'Alien_Gum', 'Alien_Other', 'Alien_Pine', 'Alien Poplar', 'Alien Silver Wattle', 'Non-Invasive Alien']\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Add additional columns for total count and total precision for each class\n",
    "conf_matrix_df['All'] = conf_matrix_df.sum(axis=1)\n",
    "conf_matrix_df.loc['All'] = conf_matrix_df.sum()\n",
    "\n",
    "# Create a Pandas DataFrame for overall accuracy\n",
    "overall_accuracy_df = pd.DataFrame([overall_accuracy], columns=['Overall Accuracy'])\n",
    "\n",
    "# Specify the save location\n",
    "output_path = r'C:\\Users\\SkosanaT\\OneDrive - Stellenbosch University\\MAPWAPS\\DataChapter1\\Results\\EMIT\\AccuracyAss\\Intraaccuracy_results.xlsx'\n",
    "\n",
    "# Write the results to an Excel file\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    overall_accuracy_df.to_excel(writer, sheet_name='Overall Accuracy', index=False)\n",
    "    conf_matrix_df.to_excel(writer, sheet_name='Confusion Matrix')\n",
    "\n",
    "# Print results\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
